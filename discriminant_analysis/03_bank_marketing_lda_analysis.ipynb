{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Linear Discriminant Analysis on Bank Marketing Dataset\n## Business Prediction: Term Deposit Subscription\n\n**Dataset Overview:**\n- Marketing campaigns of a Portuguese banking institution\n- 45,211 samples with 17 features\n- Binary classification: Will client subscribe to term deposit?\n- Features: Age, job, marital status, education, balance, duration, campaign contacts\n\n**Focus:** Business prediction and imbalanced classification"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import (\n    classification_report, \n    confusion_matrix, \n    accuracy_score,\n    roc_auc_score,\n    roc_curve,\n    precision_recall_curve,\n    f1_score,\n    matthews_corrcoef\n)\nfrom scipy import stats\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.metrics import classification_report_imbalanced\n\n# Plotting style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (14, 8)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries imported successfully!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Data Loading\n\n**Note:** This notebook expects the Bank Marketing dataset. You can download it from:\n- UCI ML Repository: https://archive.ics.uci.edu/ml/datasets/bank+marketing\n- File: `bank-additional-full.csv`\n\nFor this demo, we'll create a synthetic version with similar characteristics."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Load or create synthetic bank marketing data\ntry:\n    # Try to load real dataset\n    df = pd.read_csv('bank-additional-full.csv', sep=';')\n    print(\"Real dataset loaded successfully!\")\nexcept FileNotFoundError:\n    print(\"Creating synthetic dataset...\")\n    # Create synthetic data with similar characteristics\n    np.random.seed(42)\n    n_samples = 5000\n    \n    # Create features\n    age = np.random.normal(40, 10, n_samples).astype(int)\n    age = np.clip(age, 18, 95)\n    \n    balance = np.random.exponential(1500, n_samples).astype(int)\n    duration = np.random.exponential(250, n_samples).astype(int)\n    campaign = np.random.poisson(2.5, n_samples)\n    pdays = np.random.choice([999, *np.random.randint(0, 500, 1000)], n_samples)\n    previous = np.random.poisson(0.5, n_samples)\n    \n    # Categorical features\n    jobs = np.random.choice(['admin.', 'technician', 'services', 'management', \n                            'retired', 'blue-collar', 'unemployed', 'entrepreneur',\n                            'housemaid', 'self-employed', 'student'], n_samples)\n    marital = np.random.choice(['married', 'single', 'divorced'], n_samples, p=[0.6, 0.3, 0.1])\n    education = np.random.choice(['university.degree', 'high.school', 'basic.9y', \n                                 'professional.course', 'basic.4y', 'basic.6y'], n_samples)\n    default = np.random.choice(['no', 'yes', 'unknown'], n_samples, p=[0.97, 0.01, 0.02])\n    housing = np.random.choice(['yes', 'no', 'unknown'], n_samples, p=[0.55, 0.43, 0.02])\n    loan = np.random.choice(['yes', 'no', 'unknown'], n_samples, p=[0.15, 0.83, 0.02])\n    contact = np.random.choice(['cellular', 'telephone'], n_samples, p=[0.65, 0.35])\n    month = np.random.choice(['may', 'jun', 'jul', 'aug', 'oct', 'nov', 'dec', 'mar', 'apr', 'sep'], n_samples)\n    poutcome = np.random.choice(['nonexistent', 'failure', 'success'], n_samples, p=[0.86, 0.10, 0.04])\n    \n    # Target (imbalanced - 11% positive class)\n    # Make it dependent on features\n    prob_y = 0.05 + (duration > 300) * 0.15 + (poutcome == 'success') * 0.20\n    prob_y += (age > 60) * 0.05 + (balance > 2000) * 0.03\n    y = (np.random.random(n_samples) < prob_y).astype(int)\n    y_labels = np.where(y == 1, 'yes', 'no')\n    \n    df = pd.DataFrame({\n        'age': age,\n        'job': jobs,\n        'marital': marital,\n        'education': education,\n        'default': default,\n        'balance': balance,\n        'housing': housing,\n        'loan': loan,\n        'contact': contact,\n        'day': np.random.randint(1, 32, n_samples),\n        'month': month,\n        'duration': duration,\n        'campaign': campaign,\n        'pdays': pdays,\n        'previous': previous,\n        'poutcome': poutcome,\n        'y': y_labels\n    })\n    print(\"Synthetic dataset created!\")\n\nprint(f\"\\nDataset shape: {df.shape}\")\nprint(f\"\\nTarget distribution:\")\nprint(df['y'].value_counts())\nprint(f\"\\nPositive class percentage: {(df['y']=='yes').mean()*100:.2f}%\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Display basic information\nprint(\"\\nDataset Info:\")\nprint(df.info())\n\nprint(\"\\nFirst 10 rows:\")\ndisplay(df.head(10))\n\nprint(\"\\nStatistical Summary (Numerical Features):\")\ndisplay(df.describe())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Exploratory Data Analysis"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Identify numeric and categorical columns\nnumeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_cols = df.select_dtypes(include=['object']).columns.tolist()\ncategorical_cols.remove('y')  # Remove target\n\nprint(f\"Numeric features ({len(numeric_cols)}): {numeric_cols}\")\nprint(f\"\\nCategorical features ({len(categorical_cols)}): {categorical_cols}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Class imbalance visualization\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# Count plot\ndf['y'].value_counts().plot(kind='bar', ax=axes[0], color=['steelblue', 'coral'])\naxes[0].set_title('Target Variable Distribution (Imbalanced)')\naxes[0].set_xlabel('Subscribed to Term Deposit')\naxes[0].set_ylabel('Count')\naxes[0].set_xticklabels(['No', 'Yes'], rotation=0)\n\n# Add count labels\nfor i, v in enumerate(df['y'].value_counts().values):\n    axes[0].text(i, v + 100, str(v), ha='center', va='bottom', fontweight='bold')\n\n# Pie chart\ndf['y'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n                            colors=['steelblue', 'coral'], startangle=90)\naxes[1].set_title('Target Class Proportions')\naxes[1].set_ylabel('')\n\nplt.tight_layout()\nplt.show()\n\nimbalance_ratio = df['y'].value_counts()['no'] / df['y'].value_counts()['yes']\nprint(f\"\\nImbalance ratio (no:yes): {imbalance_ratio:.2f}:1\")\nprint(f\"This is a {'highly' if imbalance_ratio > 5 else 'moderately'} imbalanced dataset\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Numeric features distribution by target\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.ravel()\n\nfor idx, col in enumerate(numeric_cols[:6]):\n    for label in ['no', 'yes']:\n        data = df[df['y'] == label][col]\n        axes[idx].hist(data, alpha=0.6, label=label, bins=30)\n    axes[idx].set_xlabel(col)\n    axes[idx].set_ylabel('Frequency')\n    axes[idx].legend()\n    axes[idx].set_title(f'Distribution of {col} by Target')\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Box plots for key features\nkey_features = ['age', 'balance', 'duration', 'campaign']\n\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\naxes = axes.ravel()\n\nfor idx, feature in enumerate(key_features):\n    df.boxplot(column=feature, by='y', ax=axes[idx])\n    axes[idx].set_title(f'Box Plot: {feature} by Subscription')\n    axes[idx].set_xlabel('Subscribed to Term Deposit')\n    axes[idx].set_ylabel(feature)\n\nplt.suptitle('')\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Categorical features vs target\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\naxes = axes.ravel()\n\nfor idx, col in enumerate(categorical_cols[:6]):\n    ct = pd.crosstab(df[col], df['y'], normalize='index')\n    ct.plot(kind='bar', ax=axes[idx], color=['steelblue', 'coral'])\n    axes[idx].set_title(f'{col} vs Subscription Rate')\n    axes[idx].set_xlabel(col)\n    axes[idx].set_ylabel('Proportion')\n    axes[idx].legend(title='Subscribed', labels=['No', 'Yes'])\n    axes[idx].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Correlation matrix for numeric features\nplt.figure(figsize=(12, 10))\ncorr = df[numeric_cols].corr()\nsns.heatmap(corr, annot=True, cmap='coolwarm', center=0, square=True, \n            linewidths=0.5, fmt='.2f', cbar_kws={'shrink': 0.8})\nplt.title('Correlation Matrix - Numeric Features', fontsize=14, pad=20)\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Data Preprocessing"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Encode categorical variables\nle_dict = {}\ndf_encoded = df.copy()\n\nfor col in categorical_cols:\n    le = LabelEncoder()\n    df_encoded[col] = le.fit_transform(df[col])\n    le_dict[col] = le\n\n# Encode target\ndf_encoded['y'] = (df['y'] == 'yes').astype(int)\n\nprint(\"Categorical encoding complete!\")\nprint(f\"\\nEncoded dataset shape: {df_encoded.shape}\")\nprint(f\"\\nSample of encoded data:\")\ndisplay(df_encoded.head())"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Prepare features and target\nX = df_encoded.drop('y', axis=1).values\ny = df_encoded['y'].values\nfeature_names = df_encoded.drop('y', axis=1).columns.tolist()\n\nprint(f\"Feature matrix shape: {X.shape}\")\nprint(f\"Target vector shape: {y.shape}\")\nprint(f\"Number of features: {len(feature_names)}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Split data\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\nprint(f\"Training set: {X_train.shape[0]} samples\")\nprint(f\"Test set: {X_test.shape[0]} samples\")\nprint(f\"\\nTraining set class distribution:\")\nunique, counts = np.unique(y_train, return_counts=True)\nfor cls, count in zip(unique, counts):\n    print(f\"  Class {cls}: {count} ({count/len(y_train)*100:.1f}%)\")\n\nprint(f\"\\nTest set class distribution:\")\nunique, counts = np.unique(y_test, return_counts=True)\nfor cls, count in zip(unique, counts):\n    print(f\"  Class {cls}: {count} ({count/len(y_test)*100:.1f}%)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Standardize features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"Feature scaling complete!\")\nprint(f\"\\nScaled training set mean: {X_train_scaled.mean(axis=0).mean():.6f}\")\nprint(f\"Scaled training set std: {X_train_scaled.std(axis=0).mean():.6f}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. LDA on Imbalanced Data (Baseline)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Train baseline LDA\nlda_baseline = LinearDiscriminantAnalysis()\nlda_baseline.fit(X_train_scaled, y_train)\n\n# Predictions\ny_train_pred = lda_baseline.predict(X_train_scaled)\ny_test_pred = lda_baseline.predict(X_test_scaled)\n\n# Probabilities\ny_train_proba = lda_baseline.predict_proba(X_train_scaled)[:, 1]\ny_test_proba = lda_baseline.predict_proba(X_test_scaled)[:, 1]\n\nprint(\"BASELINE LDA (No Resampling)\")\nprint(\"=\" * 70)\nprint(f\"Training Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\nprint(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\nprint(f\"Test F1-Score: {f1_score(y_test, y_test_pred):.4f}\")\nprint(f\"Test ROC-AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\nprint(f\"Matthews Correlation Coefficient: {matthews_corrcoef(y_test, y_test_pred):.4f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Classification report for imbalanced data\nprint(\"\\nClassification Report (Test Set):\")\nprint(classification_report(y_test, y_test_pred, target_names=['No', 'Yes']))\n\n# Confusion matrix\ncm = confusion_matrix(y_test, y_test_pred)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\nplt.title('Confusion Matrix - Baseline LDA')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()\n\nprint(f\"\\nTrue Negatives: {cm[0,0]}\")\nprint(f\"False Positives: {cm[0,1]}\")\nprint(f\"False Negatives: {cm[1,0]}\")\nprint(f\"True Positives: {cm[1,1]}\")\nprint(f\"\\nSensitivity (Recall): {cm[1,1]/(cm[1,0]+cm[1,1]):.4f}\")\nprint(f\"Specificity: {cm[0,0]/(cm[0,0]+cm[0,1]):.4f}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. LDA with SMOTE (Handling Imbalance)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Apply SMOTE to balance classes\nsmote = SMOTE(random_state=42)\nX_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n\nprint(\"SMOTE Resampling Applied\")\nprint(\"=\" * 70)\nprint(f\"Original training set: {X_train_scaled.shape[0]} samples\")\nprint(f\"Balanced training set: {X_train_balanced.shape[0]} samples\")\n\nprint(f\"\\nOriginal class distribution:\")\nunique, counts = np.unique(y_train, return_counts=True)\nfor cls, count in zip(unique, counts):\n    print(f\"  Class {cls}: {count} ({count/len(y_train)*100:.1f}%)\")\n\nprint(f\"\\nBalanced class distribution:\")\nunique, counts = np.unique(y_train_balanced, return_counts=True)\nfor cls, count in zip(unique, counts):\n    print(f\"  Class {cls}: {count} ({count/len(y_train_balanced)*100:.1f}%)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Train LDA on balanced data\nlda_balanced = LinearDiscriminantAnalysis()\nlda_balanced.fit(X_train_balanced, y_train_balanced)\n\n# Predictions\ny_test_pred_balanced = lda_balanced.predict(X_test_scaled)\ny_test_proba_balanced = lda_balanced.predict_proba(X_test_scaled)[:, 1]\n\nprint(\"LDA WITH SMOTE RESAMPLING\")\nprint(\"=\" * 70)\nprint(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred_balanced):.4f}\")\nprint(f\"Test F1-Score: {f1_score(y_test, y_test_pred_balanced):.4f}\")\nprint(f\"Test ROC-AUC: {roc_auc_score(y_test, y_test_proba_balanced):.4f}\")\nprint(f\"Matthews Correlation Coefficient: {matthews_corrcoef(y_test, y_test_pred_balanced):.4f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Comparison of baseline vs SMOTE\nprint(\"\\nCOMPARISON: Baseline vs SMOTE\")\nprint(\"=\" * 70)\nprint(f\"{'Metric':<30} {'Baseline':>15} {'SMOTE':>15} {'Improvement':>15}\")\nprint(\"-\" * 70)\n\nmetrics = [\n    ('Accuracy', accuracy_score(y_test, y_test_pred), accuracy_score(y_test, y_test_pred_balanced)),\n    ('F1-Score', f1_score(y_test, y_test_pred), f1_score(y_test, y_test_pred_balanced)),\n    ('ROC-AUC', roc_auc_score(y_test, y_test_proba), roc_auc_score(y_test, y_test_proba_balanced)),\n    ('MCC', matthews_corrcoef(y_test, y_test_pred), matthews_corrcoef(y_test, y_test_pred_balanced))\n]\n\nfor metric_name, baseline_val, smote_val in metrics:\n    improvement = smote_val - baseline_val\n    print(f\"{metric_name:<30} {baseline_val:>15.4f} {smote_val:>15.4f} {improvement:>+15.4f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Classification report with SMOTE\nprint(\"\\nClassification Report (SMOTE):\")\nprint(classification_report(y_test, y_test_pred_balanced, target_names=['No', 'Yes']))\n\n# Confusion matrices comparison\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\ncm_baseline = confusion_matrix(y_test, y_test_pred)\ncm_smote = confusion_matrix(y_test, y_test_pred_balanced)\n\nsns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\naxes[0].set_title('Baseline LDA')\naxes[0].set_ylabel('True Label')\naxes[0].set_xlabel('Predicted Label')\n\nsns.heatmap(cm_smote, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\naxes[1].set_title('LDA with SMOTE')\naxes[1].set_ylabel('True Label')\naxes[1].set_xlabel('Predicted Label')\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. ROC and Precision-Recall Curves"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ROC curves\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# ROC Curve\nfpr_baseline, tpr_baseline, _ = roc_curve(y_test, y_test_proba)\nfpr_smote, tpr_smote, _ = roc_curve(y_test, y_test_proba_balanced)\n\naxes[0].plot(fpr_baseline, tpr_baseline, label=f'Baseline (AUC={roc_auc_score(y_test, y_test_proba):.3f})', linewidth=2)\naxes[0].plot(fpr_smote, tpr_smote, label=f'SMOTE (AUC={roc_auc_score(y_test, y_test_proba_balanced):.3f})', linewidth=2)\naxes[0].plot([0, 1], [0, 1], 'k--', label='Random')\naxes[0].set_xlabel('False Positive Rate')\naxes[0].set_ylabel('True Positive Rate')\naxes[0].set_title('ROC Curve Comparison')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\n# Precision-Recall Curve\nprecision_baseline, recall_baseline, _ = precision_recall_curve(y_test, y_test_proba)\nprecision_smote, recall_smote, _ = precision_recall_curve(y_test, y_test_proba_balanced)\n\naxes[1].plot(recall_baseline, precision_baseline, label='Baseline', linewidth=2)\naxes[1].plot(recall_smote, precision_smote, label='SMOTE', linewidth=2)\naxes[1].set_xlabel('Recall')\naxes[1].set_ylabel('Precision')\naxes[1].set_title('Precision-Recall Curve Comparison')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Feature Importance Analysis"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# LDA coefficients (using balanced model)\ncoefficients = lda_balanced.coef_[0]\n\nfeature_importance = pd.DataFrame({\n    'Feature': feature_names,\n    'Coefficient': coefficients,\n    'Abs_Coefficient': np.abs(coefficients)\n}).sort_values('Abs_Coefficient', ascending=False)\n\nprint(\"Feature Importance (LDA Coefficients):\")\nprint(\"=\" * 70)\ndisplay(feature_importance)\n\n# Plot top features\ntop_n = 15\ntop_features = feature_importance.head(top_n)\n\nplt.figure(figsize=(12, 8))\ncolors = ['red' if x < 0 else 'blue' for x in top_features['Coefficient'].values]\nplt.barh(range(top_n), top_features['Coefficient'].values[::-1], color=colors[::-1], alpha=0.7)\nplt.yticks(range(top_n), top_features['Feature'].values[::-1])\nplt.xlabel('LDA Coefficient')\nplt.title(f'Top {top_n} Most Important Features for Subscription Prediction')\nplt.axvline(x=0, color='black', linestyle='--', linewidth=1)\nplt.grid(True, alpha=0.3, axis='x')\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Business Insights and Decision Thresholds"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Analyze prediction probabilities\nplt.figure(figsize=(14, 6))\n\n# Distribution of predicted probabilities\nplt.subplot(1, 2, 1)\nfor label, name in zip([0, 1], ['No', 'Yes']):\n    mask = y_test == label\n    plt.hist(y_test_proba_balanced[mask], bins=30, alpha=0.6, label=name)\nplt.xlabel('Predicted Probability')\nplt.ylabel('Frequency')\nplt.title('Distribution of Predicted Probabilities by True Class')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# Threshold analysis\nplt.subplot(1, 2, 2)\nthresholds = np.linspace(0, 1, 100)\nf1_scores = []\nprecisions = []\nrecalls = []\n\nfor threshold in thresholds:\n    y_pred_thresh = (y_test_proba_balanced >= threshold).astype(int)\n    f1_scores.append(f1_score(y_test, y_pred_thresh))\n    precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred_thresh, average='binary')\n    precisions.append(precision)\n    recalls.append(recall)\n\nplt.plot(thresholds, f1_scores, label='F1-Score', linewidth=2)\nplt.plot(thresholds, precisions, label='Precision', linewidth=2)\nplt.plot(thresholds, recalls, label='Recall', linewidth=2)\nplt.xlabel('Decision Threshold')\nplt.ylabel('Score')\nplt.title('Performance Metrics vs Decision Threshold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.axvline(x=0.5, color='red', linestyle='--', label='Default (0.5)')\n\nplt.tight_layout()\nplt.show()\n\n# Find optimal threshold\noptimal_idx = np.argmax(f1_scores)\noptimal_threshold = thresholds[optimal_idx]\nprint(f\"\\nOptimal threshold (max F1): {optimal_threshold:.3f}\")\nprint(f\"F1-Score at optimal threshold: {f1_scores[optimal_idx]:.4f}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Business-oriented metrics\nprint(\"\\nBUSINESS METRICS\")\nprint(\"=\" * 70)\n\n# Using optimal threshold\ny_pred_optimal = (y_test_proba_balanced >= optimal_threshold).astype(int)\ncm_optimal = confusion_matrix(y_test, y_pred_optimal)\n\ntn, fp, fn, tp = cm_optimal.ravel()\n\nprint(f\"\\nUsing threshold: {optimal_threshold:.3f}\")\nprint(f\"\\nConfusion Matrix:\")\nprint(f\"  True Negatives: {tn}\")\nprint(f\"  False Positives: {fp}\")\nprint(f\"  False Negatives: {fn}\")\nprint(f\"  True Positives: {tp}\")\n\nprint(f\"\\nKey Metrics:\")\nprint(f\"  Conversion Rate (Recall/Sensitivity): {tp/(tp+fn):.2%}\")\nprint(f\"  Precision (Success Rate): {tp/(tp+fp):.2%}\")\nprint(f\"  Contacts Needed: {tp+fp} (vs {len(y_test)} if contacting all)\")\nprint(f\"  Reduction in contacts: {(1-(tp+fp)/len(y_test))*100:.1f}%\")\nprint(f\"  True positives found: {tp} out of {tp+fn} total\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. Key Insights and Recommendations"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "print(\"\\n\" + \"=\"*70)\nprint(\"KEY INSIGHTS: LDA FOR BANK MARKETING PREDICTION\")\nprint(\"=\"*70)\n\nprint(\"\\n1. CLASS IMBALANCE HANDLING\")\nprint(f\"   - Original imbalance ratio: {(y==0).sum()/(y==1).sum():.1f}:1\")\nprint(f\"   - SMOTE improved F1-score by {f1_score(y_test, y_test_pred_balanced) - f1_score(y_test, y_test_pred):.3f}\")\nprint(f\"   - Critical for minority class detection (subscribers)\")\n\nprint(\"\\n2. MODEL PERFORMANCE\")\nprint(f\"   - Test ROC-AUC: {roc_auc_score(y_test, y_test_proba_balanced):.3f}\")\nprint(f\"   - Precision: {tp/(tp+fp):.2%} (how many predicted subscribers actually subscribe)\")\nprint(f\"   - Recall: {tp/(tp+fn):.2%} (how many actual subscribers we identify)\")\n\nprint(\"\\n3. TOP PREDICTIVE FEATURES\")\ntop_3 = feature_importance.head(3)\nfor i, (_, row) in enumerate(top_3.iterrows(), 1):\n    print(f\"   {i}. {row['Feature']}: {row['Coefficient']:.4f}\")\n\nprint(\"\\n4. BUSINESS IMPACT\")\nprint(f\"   - Can reduce contacts by {(1-(tp+fp)/len(y_test))*100:.1f}% while maintaining {tp/(tp+fn):.0%} capture rate\")\nprint(f\"   - Optimal threshold: {optimal_threshold:.3f} (vs default 0.5)\")\nprint(f\"   - Focus on high-probability customers for better ROI\")\n\nprint(\"\\n5. RECOMMENDATIONS\")\nprint(\"   - Use LDA with SMOTE for better minority class detection\")\nprint(\"   - Adjust threshold based on business costs (contact vs lost customer)\")\nprint(f\"   - Focus marketing on customers with probability > {optimal_threshold:.2f}\")\nprint(\"   - Monitor top features for campaign optimization\")\n\nprint(\"\\n\" + \"=\"*70)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Summary\n\n### What We Learned:\n\n1. **Handling Imbalanced Data**: SMOTE significantly improves detection of minority class (subscribers) without sacrificing overall performance\n\n2. **Business-Oriented Metrics**: ROC-AUC and precision-recall curves are more informative than accuracy for imbalanced datasets\n\n3. **Feature Importance**: Identified key predictors for term deposit subscription\n\n4. **Threshold Optimization**: Adjusting decision threshold based on business costs can improve ROI\n\n5. **Practical Application**: Model can guide targeted marketing campaigns\n\n### Why Bank Marketing is Good for LDA:\n- Real-world business problem with direct ROI implications\n- Class imbalance teaches proper evaluation techniques\n- Mix of numerical and categorical features\n- Interpretable coefficients guide business decisions\n- Demonstrates importance of preprocessing and resampling\n\n### Next Steps:\n- Experiment with different SMOTE variants (ADASYN, BorderlineSMOTE)\n- Try cost-sensitive learning approaches\n- Compare with ensemble methods (Random Forest, XGBoost)\n- Perform feature engineering for better predictions\n- Conduct temporal validation (time-based splits)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}