{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis on Wine Recognition Dataset\n",
    "## Multi-class Classification with High Dimensionality\n",
    "\n",
    "**Dataset Overview:**\n",
    "- 178 samples, 13 features (chemical analysis)\n",
    "- 3 classes (wine cultivars)\n",
    "- High-dimensional feature space\n",
    "- Features: Alcohol, Malic acid, Ash, Alkalinity, Magnesium, Phenols, Flavanoids, etc.\n",
    "\n",
    "**Focus:** Feature separation and multi-class LDA in high dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "wine = load_wine()\n",
    "X = wine.data\n",
    "y = wine.target\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=wine.feature_names)\n",
    "df['wine_class'] = pd.Categorical.from_codes(y, wine.target_names)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(f\"\\nFeatures ({len(wine.feature_names)}):\")\n",
    "for i, name in enumerate(wine.feature_names, 1):\n",
    "    print(f\"{i:2d}. {name}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['wine_class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df[wine.feature_names].describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum().sum(), \"missing values found\")\n",
    "\n",
    "print(\"\\nFeature Value Ranges:\")\n",
    "ranges_df = pd.DataFrame({\n",
    "    'Min': df[wine.feature_names].min(),\n",
    "    'Max': df[wine.feature_names].max(),\n",
    "    'Range': df[wine.feature_names].max() - df[wine.feature_names].min(),\n",
    "    'Mean': df[wine.feature_names].mean()\n",
    "})\n",
    "display(ranges_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Count plot\n",
    "df['wine_class'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Wine Class Distribution')\n",
    "axes[0].set_xlabel('Wine Class')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(wine.target_names, rotation=45)\n",
    "\n",
    "# Pie chart\n",
    "df['wine_class'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "axes[1].set_title('Wine Class Proportions')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions by class\n",
    "# Select top 6 features for visualization\n",
    "top_features = wine.feature_names[:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    for class_name in wine.target_names:\n",
    "        data = df[df['wine_class'] == class_name][feature]\n",
    "        axes[idx].hist(data, alpha=0.5, label=class_name, bins=15)\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_title(f'Distribution of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation = df[wine.feature_names].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Matrix - Wine Dataset', fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated features\n",
    "print(\"\\nHighly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "print(\"=\" * 60)\n",
    "corr_pairs = []\n",
    "for i in range(len(correlation.columns)):\n",
    "    for j in range(i+1, len(correlation.columns)):\n",
    "        if abs(correlation.iloc[i, j]) > 0.7:\n",
    "            corr_pairs.append((correlation.columns[i], correlation.columns[j], correlation.iloc[i, j]))\n",
    "\n",
    "for feat1, feat2, corr_val in sorted(corr_pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "    print(f\"{feat1:30s} <-> {feat2:30s} : {corr_val:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for key features\n",
    "key_features = ['alcohol', 'flavanoids', 'color_intensity', 'proline']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    df.boxplot(column=feature, by='wine_class', ax=axes[idx])\n",
    "    axes[idx].set_title(f'Box Plot: {feature}')\n",
    "    axes[idx].set_xlabel('Wine Class')\n",
    "    axes[idx].set_ylabel(feature)\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for selected features\n",
    "selected_features = ['alcohol', 'flavanoids', 'color_intensity', 'od280/od315_of_diluted_wines']\n",
    "pairplot_df = df[selected_features + ['wine_class']]\n",
    "\n",
    "sns.pairplot(pairplot_df, hue='wine_class', diag_kind='kde', height=3)\n",
    "plt.suptitle('Pairplot of Selected Wine Features', y=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nFeature dimensions: {X_train.shape[1]}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {wine.target_names[cls]}: {count}\")\n",
    "\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {wine.target_names[cls]}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (critical for wine dataset due to different scales)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature Scaling Statistics:\")\n",
    "print(\"=\" * 70)\n",
    "scaling_stats = pd.DataFrame({\n",
    "    'Feature': wine.feature_names,\n",
    "    'Original_Mean': X_train.mean(axis=0),\n",
    "    'Scaled_Mean': X_train_scaled.mean(axis=0),\n",
    "    'Original_Std': X_train.std(axis=0),\n",
    "    'Scaled_Std': X_train_scaled.std(axis=0)\n",
    "})\n",
    "display(scaling_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = lda.predict(X_train_scaled)\n",
    "y_test_pred = lda.predict(X_test_scaled)\n",
    "\n",
    "# Probabilities\n",
    "y_train_proba = lda.predict_proba(X_train_scaled)\n",
    "y_test_proba = lda.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"LDA Model Trained Successfully!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Number of components: {lda.n_components}\")\n",
    "print(f\"Classes: {lda.classes_}\")\n",
    "print(f\"Number of features: {lda.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nMODEL PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Generalization Gap: {train_accuracy - test_accuracy:.4f}\")\n",
    "\n",
    "if train_accuracy - test_accuracy < 0.05:\n",
    "    print(\"✓ Model shows good generalization (gap < 5%)\")\n",
    "elif train_accuracy - test_accuracy < 0.10:\n",
    "    print(\"⚠ Model shows moderate overfitting (gap 5-10%)\")\n",
    "else:\n",
    "    print(\"✗ Model shows significant overfitting (gap > 10%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with stratified folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(lda, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "print(\"\\nCROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Fold Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
    "print(f\"Std CV Score: {cv_scores.std():.4f}\")\n",
    "print(f\"95% Confidence Interval: [{cv_scores.mean() - 1.96*cv_scores.std():.4f}, \"\n",
    "      f\"{cv_scores.mean() + 1.96*cv_scores.std():.4f}]\")\n",
    "\n",
    "# Visualize CV scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 6), cv_scores, 'bo-', linewidth=2, markersize=10)\n",
    "plt.axhline(y=cv_scores.mean(), color='r', linestyle='--', label=f'Mean: {cv_scores.mean():.4f}')\n",
    "plt.fill_between(range(1, 6), \n",
    "                 cv_scores.mean() - cv_scores.std(), \n",
    "                 cv_scores.mean() + cv_scores.std(), \n",
    "                 alpha=0.2, color='red')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Cross-Validation Scores Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0.8, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nCLASSIFICATION REPORT (Test Set)\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=wine.target_names))\n",
    "\n",
    "# Per-class metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_test, y_test_pred)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': wine.target_names,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "print(\"\\nPer-Class Metrics Summary:\")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=wine.target_names, yticklabels=wine.target_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Normalized\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=wine.target_names, yticklabels=wine.target_names,\n",
    "            cbar_kws={'label': 'Proportion'})\n",
    "axes[1].set_title('Confusion Matrix (Normalized)')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis of misclassifications\n",
    "print(\"\\nMisclassification Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "for i in range(len(wine.target_names)):\n",
    "    for j in range(len(wine.target_names)):\n",
    "        if i != j and cm[i, j] > 0:\n",
    "            print(f\"{wine.target_names[i]} misclassified as {wine.target_names[j]}: {cm[i, j]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LDA Components and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Scalings (Linear Discriminants)\n",
    "print(\"LDA SCALINGS (Linear Discriminant Coefficients)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "scalings_df = pd.DataFrame(\n",
    "    lda.scalings_,\n",
    "    index=wine.feature_names,\n",
    "    columns=[f'LD{i+1}' for i in range(lda.scalings_.shape[1])]\n",
    ")\n",
    "display(scalings_df)\n",
    "\n",
    "# Visualize coefficients\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "for i in range(lda.scalings_.shape[1]):\n",
    "    coef_sorted = scalings_df[f'LD{i+1}'].sort_values()\n",
    "    colors = ['red' if x < 0 else 'blue' for x in coef_sorted.values]\n",
    "    axes[i].barh(range(len(coef_sorted)), coef_sorted.values, color=colors, alpha=0.7)\n",
    "    axes[i].set_yticks(range(len(coef_sorted)))\n",
    "    axes[i].set_yticklabels(coef_sorted.index, fontsize=9)\n",
    "    axes[i].set_xlabel('Coefficient Value')\n",
    "    axes[i].set_title(f'LD{i+1} Feature Coefficients')\n",
    "    axes[i].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "    axes[i].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance based on absolute coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': wine.feature_names,\n",
    "    'LD1_Abs': np.abs(scalings_df['LD1']),\n",
    "    'LD2_Abs': np.abs(scalings_df['LD2']),\n",
    "    'Total_Importance': np.abs(scalings_df['LD1']) + np.abs(scalings_df['LD2'])\n",
    "}).sort_values('Total_Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (based on absolute LD coefficients):\")\n",
    "display(feature_importance)\n",
    "\n",
    "# Visualize top features\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_n = 10\n",
    "top_features = feature_importance.head(top_n)\n",
    "plt.barh(range(top_n), top_features['Total_Importance'].values[::-1], alpha=0.7)\n",
    "plt.yticks(range(top_n), top_features['Feature'].values[::-1])\n",
    "plt.xlabel('Total Importance (Sum of Absolute Coefficients)')\n",
    "plt.title(f'Top {top_n} Most Important Features for LDA')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "print(\"\\nEXPLAINED VARIANCE RATIO\")\n",
    "print(\"=\" * 70)\n",
    "for i, var in enumerate(lda.explained_variance_ratio_):\n",
    "    print(f\"LD{i+1}: {var:.6f} ({var*100:.2f}%)\")\n",
    "\n",
    "cumulative_var = np.cumsum(lda.explained_variance_ratio_)\n",
    "print(f\"\\nCumulative variance: {cumulative_var}\")\n",
    "print(f\"Total variance explained: {cumulative_var[-1]*100:.2f}%\")\n",
    "\n",
    "# Plot variance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Individual variance\n",
    "axes[0].bar(range(1, len(lda.explained_variance_ratio_) + 1), \n",
    "            lda.explained_variance_ratio_, color='steelblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Linear Discriminant')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('Variance Explained by Each Component')\n",
    "axes[0].set_xticks(range(1, len(lda.explained_variance_ratio_) + 1))\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Cumulative variance\n",
    "axes[1].plot(range(1, len(cumulative_var) + 1), cumulative_var, 'bo-', linewidth=2, markersize=10)\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].set_title('Cumulative Variance Explained')\n",
    "axes[1].set_xticks(range(1, len(cumulative_var) + 1))\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LDA Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to LDA space\n",
    "X_train_lda = lda.transform(X_train_scaled)\n",
    "X_test_lda = lda.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Original space: {X_train_scaled.shape[1]} dimensions\")\n",
    "print(f\"LDA space: {X_train_lda.shape[1]} dimensions\")\n",
    "print(f\"Dimensionality reduction: {X_train_scaled.shape[1]} → {X_train_lda.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D visualization of LDA space\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Training data\n",
    "for i, wine_class in enumerate(wine.target_names):\n",
    "    mask = y_train == i\n",
    "    axes[0].scatter(X_train_lda[mask, 0], X_train_lda[mask, 1], \n",
    "                   label=wine_class, alpha=0.7, s=80, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "axes[0].set_xlabel(f'LD1 ({lda.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "axes[0].set_ylabel(f'LD2 ({lda.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "axes[0].set_title('Training Data in LDA Space')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test data with predictions\n",
    "for i, wine_class in enumerate(wine.target_names):\n",
    "    # Correct predictions\n",
    "    mask_correct = (y_test == i) & (y_test_pred == i)\n",
    "    axes[1].scatter(X_test_lda[mask_correct, 0], X_test_lda[mask_correct, 1],\n",
    "                   label=f'{wine_class} (correct)', alpha=0.7, s=80, \n",
    "                   edgecolors='black', linewidths=0.5)\n",
    "    \n",
    "    # Incorrect predictions\n",
    "    mask_incorrect = (y_test == i) & (y_test_pred != i)\n",
    "    if mask_incorrect.any():\n",
    "        axes[1].scatter(X_test_lda[mask_incorrect, 0], X_test_lda[mask_incorrect, 1],\n",
    "                       marker='x', s=200, linewidths=3, color='red',\n",
    "                       label=f'{wine_class} (misclassified)')\n",
    "\n",
    "axes[1].set_xlabel(f'LD1 ({lda.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "axes[1].set_ylabel(f'LD2 ({lda.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "axes[1].set_title('Test Data in LDA Space (with Misclassifications)')\n",
    "axes[1].legend(loc='best', fontsize=8)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D distributions along each LD\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "for ld_idx in range(2):\n",
    "    for i, wine_class in enumerate(wine.target_names):\n",
    "        mask = y_train == i\n",
    "        axes[ld_idx].hist(X_train_lda[mask, ld_idx], alpha=0.5, \n",
    "                         label=wine_class, bins=20, edgecolor='black')\n",
    "    \n",
    "    axes[ld_idx].set_xlabel(f'LD{ld_idx+1}')\n",
    "    axes[ld_idx].set_ylabel('Frequency')\n",
    "    axes[ld_idx].set_title(f'Distribution of Classes along LD{ld_idx+1}')\n",
    "    axes[ld_idx].legend()\n",
    "    axes[ld_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison with QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train QDA for comparison\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_test_pred_qda = qda.predict(X_test_scaled)\n",
    "qda_accuracy = accuracy_score(y_test, y_test_pred_qda)\n",
    "\n",
    "print(\"COMPARISON: LDA vs QDA\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"LDA Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"QDA Test Accuracy: {qda_accuracy:.4f} ({qda_accuracy*100:.2f}%)\")\n",
    "print(f\"\\nDifference: {abs(test_accuracy - qda_accuracy):.4f}\")\n",
    "\n",
    "if test_accuracy > qda_accuracy:\n",
    "    print(\"→ LDA performs better (covariance assumption holds)\")\n",
    "elif qda_accuracy > test_accuracy:\n",
    "    print(\"→ QDA performs better (different covariances per class)\")\n",
    "else:\n",
    "    print(\"→ LDA and QDA perform equally well\")\n",
    "\n",
    "# Detailed comparison\n",
    "print(\"\\nQDA Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_qda, target_names=wine.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LDA with PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Train LDA on PCA-reduced data\n",
    "lda_on_pca = LinearDiscriminantAnalysis()\n",
    "lda_on_pca.fit(X_train_pca, y_train)\n",
    "pca_lda_accuracy = lda_on_pca.score(X_test_pca, y_test)\n",
    "\n",
    "print(\"COMPARISON: LDA vs PCA+LDA\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"LDA (13D → 2D): {test_accuracy:.4f}\")\n",
    "print(f\"PCA (13D → 2D) + LDA: {pca_lda_accuracy:.4f}\")\n",
    "print(f\"\\nPCA explained variance: {pca.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "print(f\"LDA explained variance: {lda.explained_variance_ratio_.sum()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA vs LDA projections side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# PCA projection\n",
    "for i, wine_class in enumerate(wine.target_names):\n",
    "    mask = y_train == i\n",
    "    axes[0].scatter(X_train_pca[mask, 0], X_train_pca[mask, 1],\n",
    "                   label=wine_class, alpha=0.7, s=80, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "axes[0].set_title('PCA Projection (Unsupervised)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# LDA projection\n",
    "for i, wine_class in enumerate(wine.target_names):\n",
    "    mask = y_train == i\n",
    "    axes[1].scatter(X_train_lda[mask, 0], X_train_lda[mask, 1],\n",
    "                   label=wine_class, alpha=0.7, s=80, edgecolors='black', linewidths=0.5)\n",
    "\n",
    "axes[1].set_xlabel(f'LD1 ({lda.explained_variance_ratio_[0]*100:.1f}% variance)')\n",
    "axes[1].set_ylabel(f'LD2 ({lda.explained_variance_ratio_[1]*100:.1f}% variance)')\n",
    "axes[1].set_title('LDA Projection (Supervised)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('PCA vs LDA: Class Separation Comparison', y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Difference:\")\n",
    "print(\"- PCA maximizes variance (unsupervised)\")\n",
    "print(\"- LDA maximizes class separation (supervised)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Insights and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "top_3_features = feature_importance.head(3)['Feature'].tolist()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS: LDA ON WINE RECOGNITION DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. DIMENSIONALITY REDUCTION\")\n",
    "print(f\"   - Original: {X.shape[1]} features\")\n",
    "print(f\"   - LDA: {lda.n_components} components\")\n",
    "print(f\"   - Variance retained: {lda.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "print(f\"   - Effective compression: {X.shape[1]/lda.n_components:.1f}x\")\n",
    "\n",
    "print(\"\\n2. CLASSIFICATION PERFORMANCE\")\n",
    "print(f\"   - Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   - Cross-validation: {cv_scores.mean()*100:.2f}% ± {cv_scores.std()*100:.2f}%\")\n",
    "print(f\"   - LDA vs QDA: {'LDA better' if test_accuracy > qda_accuracy else 'QDA better' if qda_accuracy > test_accuracy else 'Equal'}\")\n",
    "\n",
    "print(\"\\n3. TOP DISCRIMINATIVE FEATURES\")\n",
    "for i, feat in enumerate(top_3_features, 1):\n",
    "    importance = feature_importance[feature_importance['Feature'] == feat]['Total_Importance'].values[0]\n",
    "    print(f\"   {i}. {feat}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\n4. CLASS SEPARATION\")\n",
    "print(f\"   - LD1 explains {lda.explained_variance_ratio_[0]*100:.1f}% of between-class variance\")\n",
    "print(f\"   - LD2 explains {lda.explained_variance_ratio_[1]*100:.1f}% of between-class variance\")\n",
    "print(f\"   - Classes are {'well' if test_accuracy > 0.95 else 'moderately'} separated\")\n",
    "\n",
    "print(\"\\n5. MODEL CHARACTERISTICS\")\n",
    "print(f\"   - Generalization gap: {(train_accuracy - test_accuracy)*100:.2f}%\")\n",
    "print(f\"   - Misclassifications: {(y_test != y_test_pred).sum()} / {len(y_test)}\")\n",
    "print(f\"   - Average prediction confidence: {y_test_proba.max(axis=1).mean():.4f}\")\n",
    "\n",
    "print(\"\\n6. COMPUTATIONAL EFFICIENCY\")\n",
    "print(f\"   - High-dimensional data (13 features) reduced to {lda.n_components}D\")\n",
    "print(f\"   - Suitable for real-time wine classification\")\n",
    "print(f\"   - Simple linear model with interpretable coefficients\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **High-Dimensional LDA**: Successfully reduced 13 chemical features to 2 discriminant components while maintaining excellent classification performance\n",
    "\n",
    "2. **Feature Importance**: Identified which chemical properties are most discriminative for wine classification\n",
    "\n",
    "3. **LDA vs PCA**: LDA provides better class separation than PCA because it's supervised (uses class labels)\n",
    "\n",
    "4. **Practical Application**: The model can effectively classify wine cultivars based on chemical analysis\n",
    "\n",
    "### Why Wine Dataset is Good for LDA:\n",
    "- High dimensionality (13 features) demonstrates LDA's ability to find optimal low-dimensional projections\n",
    "- Chemical features have different scales, highlighting importance of standardization\n",
    "- Clear class structure allows LDA to find discriminative directions\n",
    "- Small sample size (178) shows LDA works well even with limited data\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with feature selection techniques\n",
    "- Try regularized LDA for better generalization\n",
    "- Compare with other classifiers (Random Forest, SVM)\n",
    "- Explore ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
