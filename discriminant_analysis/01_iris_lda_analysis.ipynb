{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis on Iris Dataset\n",
    "## The 'Hello World' of LDA\n",
    "\n",
    "**Dataset Overview:**\n",
    "- 150 samples, 4 features (sepal length/width, petal length/width)\n",
    "- 3 classes (Setosa, Versicolor, Virginica)\n",
    "- Features are normally distributed\n",
    "- Classes are well-separated\n",
    "\n",
    "**Focus:** Classification Basics & LDA Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "from scipy import stats\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create DataFrame for easier manipulation\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(y, iris.target_names)\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print(\"Statistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of features by species\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(iris.feature_names):\n",
    "    for species in iris.target_names:\n",
    "        data = df[df['species'] == species][col]\n",
    "        axes[idx].hist(data, alpha=0.5, label=species, bins=20)\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(df, hue='species', diag_kind='kde', height=2.5)\n",
    "plt.suptitle('Pairplot of Iris Features by Species', y=1.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation = df[iris.feature_names].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for each feature\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(iris.feature_names):\n",
    "    df.boxplot(column=col, by='species', ax=axes[idx])\n",
    "    axes[idx].set_title(f'Box Plot of {col}')\n",
    "    axes[idx].set_xlabel('Species')\n",
    "    axes[idx].set_ylabel(col)\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Assumptions for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for normality (Shapiro-Wilk test)\n",
    "print(\"Normality Tests (Shapiro-Wilk):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for species in iris.target_names:\n",
    "    print(f\"\\n{species.upper()}:\")\n",
    "    for col in iris.feature_names:\n",
    "        data = df[df['species'] == species][col]\n",
    "        stat, p_value = stats.shapiro(data)\n",
    "        result = \"Normal\" if p_value > 0.05 else \"Non-normal\"\n",
    "        print(f\"  {col}: p-value = {p_value:.4f} ({result})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plots for normality visualization\n",
    "fig, axes = plt.subplots(3, 4, figsize=(18, 12))\n",
    "\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    for j, col in enumerate(iris.feature_names):\n",
    "        data = df[df['species'] == species][col]\n",
    "        stats.probplot(data, dist=\"norm\", plot=axes[i, j])\n",
    "        axes[i, j].set_title(f'{species} - {col}')\n",
    "\n",
    "plt.suptitle('Q-Q Plots for Normality Check', y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for homogeneity of covariance (Box's M test approximation)\n",
    "# Using Levene's test for equality of variances as a simpler alternative\n",
    "print(\"\\nHomogeneity of Variance Tests (Levene's test):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for col in iris.feature_names:\n",
    "    groups = [df[df['species'] == species][col].values for species in iris.target_names]\n",
    "    stat, p_value = stats.levene(*groups)\n",
    "    result = \"Equal variances\" if p_value > 0.05 else \"Unequal variances\"\n",
    "    print(f\"{col}: p-value = {p_value:.4f} ({result})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (optional for LDA, but good practice)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Feature scaling complete!\")\n",
    "print(\"\\nScaled feature means (should be ~0):\")\n",
    "print(X_train_scaled.mean(axis=0))\n",
    "print(\"\\nScaled feature std devs (should be ~1):\")\n",
    "print(X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_train_pred = lda.predict(X_train_scaled)\n",
    "y_test_pred = lda.predict(X_test_scaled)\n",
    "\n",
    "# Get probability predictions\n",
    "y_train_proba = lda.predict_proba(X_train_scaled)\n",
    "y_test_proba = lda.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"LDA Model trained successfully!\")\n",
    "print(f\"\\nNumber of discriminant components: {lda.n_components}\")\n",
    "print(f\"Classes: {lda.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Overfitting Check: {train_accuracy - test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "cv_scores = cross_val_score(lda, X_train_scaled, y_train, cv=5)\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_test_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - LDA on Iris Dataset')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names,\n",
    "            cbar_kws={'label': 'Proportion'})\n",
    "plt.title('Normalized Confusion Matrix - LDA on Iris Dataset')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA coefficients (linear discriminants)\n",
    "print(\"LDA Coefficients (Scalings):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "scalings_df = pd.DataFrame(\n",
    "    lda.scalings_,\n",
    "    index=iris.feature_names,\n",
    "    columns=[f'LD{i+1}' for i in range(lda.scalings_.shape[1])]\n",
    ")\n",
    "display(scalings_df)\n",
    "\n",
    "# Visualize coefficients\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for i in range(lda.scalings_.shape[1]):\n",
    "    axes[i].barh(iris.feature_names, scalings_df[f'LD{i+1}'])\n",
    "    axes[i].set_xlabel('Coefficient Value')\n",
    "    axes[i].set_title(f'Linear Discriminant {i+1} Coefficients')\n",
    "    axes[i].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "print(\"=\" * 60)\n",
    "for i, var in enumerate(lda.explained_variance_ratio_):\n",
    "    print(f\"LD{i+1}: {var:.4f} ({var*100:.2f}%)\")\n",
    "\n",
    "# Cumulative variance\n",
    "cumulative_var = np.cumsum(lda.explained_variance_ratio_)\n",
    "print(f\"\\nCumulative variance explained: {cumulative_var}\")\n",
    "\n",
    "# Plot explained variance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot\n",
    "axes[0].bar(range(1, len(lda.explained_variance_ratio_) + 1), \n",
    "            lda.explained_variance_ratio_)\n",
    "axes[0].set_xlabel('Linear Discriminant')\n",
    "axes[0].set_ylabel('Explained Variance Ratio')\n",
    "axes[0].set_title('Explained Variance by Component')\n",
    "axes[0].set_xticks(range(1, len(lda.explained_variance_ratio_) + 1))\n",
    "\n",
    "# Cumulative plot\n",
    "axes[1].plot(range(1, len(cumulative_var) + 1), cumulative_var, 'bo-')\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Explained Variance')\n",
    "axes[1].set_title('Cumulative Explained Variance')\n",
    "axes[1].set_xticks(range(1, len(cumulative_var) + 1))\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class means in the original space\n",
    "print(\"\\nClass Means (Original Feature Space):\")\n",
    "print(\"=\" * 60)\n",
    "means_df = pd.DataFrame(\n",
    "    lda.means_,\n",
    "    index=iris.target_names,\n",
    "    columns=iris.feature_names\n",
    ")\n",
    "display(means_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dimensionality Reduction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data to LDA space\n",
    "X_train_lda = lda.transform(X_train_scaled)\n",
    "X_test_lda = lda.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Original feature space: {X_train_scaled.shape[1]} dimensions\")\n",
    "print(f\"LDA feature space: {X_train_lda.shape[1]} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data in LDA space\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Training data\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = y_train == i\n",
    "    axes[0].scatter(X_train_lda[mask, 0], X_train_lda[mask, 1], \n",
    "                   label=species, alpha=0.7, s=50, edgecolors='black')\n",
    "axes[0].set_xlabel('LD1 (First Linear Discriminant)')\n",
    "axes[0].set_ylabel('LD2 (Second Linear Discriminant)')\n",
    "axes[0].set_title('Training Data in LDA Space')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Test data\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask = y_test == i\n",
    "    axes[1].scatter(X_test_lda[mask, 0], X_test_lda[mask, 1], \n",
    "                   label=species, alpha=0.7, s=50, edgecolors='black')\n",
    "axes[1].set_xlabel('LD1 (First Linear Discriminant)')\n",
    "axes[1].set_ylabel('LD2 (Second Linear Discriminant)')\n",
    "axes[1].set_title('Test Data in LDA Space')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D visualization (using only LD1)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Histogram\n",
    "for i, species in enumerate(iris.target_names):\n",
    "    mask_train = y_train == i\n",
    "    axes[0].hist(X_train_lda[mask_train, 0], alpha=0.5, label=species, bins=20)\n",
    "\n",
    "axes[0].set_xlabel('LD1 (First Linear Discriminant)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Classes along LD1')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Violin plot\n",
    "ld1_data = pd.DataFrame({\n",
    "    'LD1': X_train_lda[:, 0],\n",
    "    'Species': [iris.target_names[i] for i in y_train]\n",
    "})\n",
    "sns.violinplot(data=ld1_data, x='Species', y='LD1', ax=axes[1])\n",
    "axes[1].set_title('Class Separation on LD1 (Violin Plot)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Decision Boundaries (2D Projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid for decision boundary\n",
    "def plot_decision_boundary(X, y, model, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')\n",
    "    \n",
    "    for i, species in enumerate(iris.target_names):\n",
    "        mask = y == i\n",
    "        plt.scatter(X[mask, 0], X[mask, 1], label=species, \n",
    "                   edgecolors='black', s=100, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.colorbar(label='Predicted Class')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Train LDA on the LDA-transformed space for visualization\n",
    "lda_viz = LinearDiscriminantAnalysis()\n",
    "lda_viz.fit(X_train_lda, y_train)\n",
    "\n",
    "plot_decision_boundary(X_train_lda, y_train, lda_viz, \n",
    "                       'Decision Boundaries in LDA Space (Training Data)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Probability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze prediction probabilities\n",
    "prob_df = pd.DataFrame(\n",
    "    y_test_proba,\n",
    "    columns=[f'P({species})' for species in iris.target_names]\n",
    ")\n",
    "prob_df['True_Class'] = [iris.target_names[i] for i in y_test]\n",
    "prob_df['Predicted_Class'] = [iris.target_names[i] for i in y_test_pred]\n",
    "prob_df['Correct'] = prob_df['True_Class'] == prob_df['Predicted_Class']\n",
    "\n",
    "print(\"Sample Predictions with Probabilities:\")\n",
    "display(prob_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction confidence\n",
    "max_probs = y_test_proba.max(axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram of prediction confidence\n",
    "axes[0].hist(max_probs, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Maximum Probability')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of Prediction Confidence')\n",
    "axes[0].axvline(x=max_probs.mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {max_probs.mean():.3f}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Confidence by correctness\n",
    "correct_probs = max_probs[y_test == y_test_pred]\n",
    "incorrect_probs = max_probs[y_test != y_test_pred]\n",
    "\n",
    "axes[1].hist([correct_probs, incorrect_probs], bins=20, \n",
    "             label=['Correct', 'Incorrect'], alpha=0.7, edgecolor='black')\n",
    "axes[1].set_xlabel('Maximum Probability')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Prediction Confidence: Correct vs Incorrect')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average confidence for correct predictions: {correct_probs.mean():.4f}\")\n",
    "if len(incorrect_probs) > 0:\n",
    "    print(f\"Average confidence for incorrect predictions: {incorrect_probs.mean():.4f}\")\n",
    "else:\n",
    "    print(\"No incorrect predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KEY INSIGHTS FROM LDA ON IRIS DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n1. MODEL PERFORMANCE\")\n",
    "print(f\"   - Test Accuracy: {test_accuracy:.2%}\")\n",
    "print(f\"   - Cross-validation Score: {cv_scores.mean():.2%} (+/- {cv_scores.std() * 2:.2%})\")\n",
    "print(f\"   - The model shows {'excellent' if test_accuracy > 0.95 else 'good'} performance\")\n",
    "\n",
    "print(f\"\\n2. DIMENSIONALITY REDUCTION\")\n",
    "print(f\"   - Reduced from {X.shape[1]} to {lda.n_components} dimensions\")\n",
    "print(f\"   - LD1 explains {lda.explained_variance_ratio_[0]:.2%} of variance\")\n",
    "print(f\"   - LD2 explains {lda.explained_variance_ratio_[1]:.2%} of variance\")\n",
    "print(f\"   - Total variance explained: {lda.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "print(f\"\\n3. FEATURE IMPORTANCE\")\n",
    "most_important_ld1 = scalings_df['LD1'].abs().idxmax()\n",
    "most_important_ld2 = scalings_df['LD2'].abs().idxmax()\n",
    "print(f\"   - Most important for LD1: {most_important_ld1}\")\n",
    "print(f\"   - Most important for LD2: {most_important_ld2}\")\n",
    "\n",
    "print(f\"\\n4. CLASS SEPARATION\")\n",
    "print(f\"   - Classes are well-separated in LDA space\")\n",
    "print(f\"   - Setosa is the most easily distinguished class\")\n",
    "if len(incorrect_probs) > 0:\n",
    "    print(f\"   - Some overlap between Versicolor and Virginica\")\n",
    "\n",
    "print(f\"\\n5. ASSUMPTIONS\")\n",
    "print(f\"   - Features are approximately normally distributed\")\n",
    "print(f\"   - Covariance homogeneity is reasonably satisfied\")\n",
    "print(f\"   - LDA assumptions are well met for this dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Data exploration** and understanding of the Iris dataset\n",
    "2. **Assumption testing** for LDA (normality and homogeneity)\n",
    "3. **Model training** and evaluation with LDA\n",
    "4. **Dimensionality reduction** from 4D to 2D\n",
    "5. **Visualization** of decision boundaries and class separation\n",
    "6. **Interpretation** of LDA components and feature importance\n",
    "\n",
    "The Iris dataset is ideal for learning LDA because:\n",
    "- Features are approximately normally distributed\n",
    "- Classes have similar covariances\n",
    "- Clear linear separability between classes\n",
    "- Small size allows for quick experimentation\n",
    "\n",
    "**Next Steps:**\n",
    "- Try QDA (Quadratic Discriminant Analysis) for comparison\n",
    "- Experiment with feature selection\n",
    "- Compare with other classifiers (Logistic Regression, SVM, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
