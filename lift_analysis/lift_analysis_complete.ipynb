{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Lift Analysis Notebook\n",
    "\n",
    "This notebook covers all three types of lift analysis:\n",
    "1. **Market Basket Analysis** - Association Rule Lift\n",
    "2. **Predictive Modeling** - Targeting Efficiency Lift\n",
    "3. **A/B Testing** - Incremental Impact Lift\n",
    "\n",
    "## Lift Definition\n",
    "\n",
    "**Lift is a \"Multiplier of Success\"** - it measures how much better your specific approach performs compared to a baseline of \"business as usual\" or \"random chance.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pandas numpy matplotlib seaborn mlxtend scikit-learn scipy statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Market Basket Analysis - Association Rule Lift\n",
    "\n",
    "## Definition\n",
    "Measures how much more likely a customer is to buy Item B given they bought Item A, compared to buying B randomly.\n",
    "\n",
    "## Formula\n",
    "$$\\text{Lift} = \\frac{P(A \\cap B)}{P(A) \\times P(B)}$$\n",
    "\n",
    "## Interpretation\n",
    "- **Lift = 1.0**: Items are independent (no relationship)\n",
    "- **Lift > 1.0**: Items are positively correlated (bought together more than random)\n",
    "- **Lift < 1.0**: Items are negatively correlated (bought together less than random)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_groceries_data():\n",
    "    \"\"\"\n",
    "    Load and prepare groceries dataset\n",
    "    \n",
    "    For real data, load from:\n",
    "    https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset\n",
    "    \n",
    "    Expected format: CSV with 'Member_number' and 'itemDescription' columns\n",
    "    OR: List of transactions where each transaction is a list of items\n",
    "    \"\"\"\n",
    "    # Sample transactions for demonstration\n",
    "    # Replace this with your actual data loading code\n",
    "    transactions = [\n",
    "        ['milk', 'bread', 'butter'],\n",
    "        ['beer', 'diapers', 'bread'],\n",
    "        ['milk', 'bread', 'butter', 'cheese'],\n",
    "        ['beer', 'diapers'],\n",
    "        ['milk', 'bread', 'butter', 'eggs'],\n",
    "        ['beer', 'diapers', 'chips'],\n",
    "        ['milk', 'cheese'],\n",
    "        ['bread', 'butter', 'eggs'],\n",
    "        ['beer', 'diapers', 'bread', 'chips'],\n",
    "        ['milk', 'bread', 'cheese', 'eggs'],\n",
    "        ['coffee', 'sugar', 'milk'],\n",
    "        ['wine', 'cheese', 'crackers'],\n",
    "        ['beer', 'chips', 'salsa'],\n",
    "        ['pasta', 'tomato sauce', 'cheese'],\n",
    "        ['chicken', 'rice', 'vegetables'],\n",
    "    ]\n",
    "    \n",
    "    # If loading from CSV:\n",
    "    # df = pd.read_csv('groceries.csv')\n",
    "    # transactions = df.groupby('Member_number')['itemDescription'].apply(list).tolist()\n",
    "    \n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_market_basket_analysis(transactions, min_support=0.2, min_threshold=1.0):\n",
    "    \"\"\"\n",
    "    Perform market basket analysis and calculate lift\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    transactions : list of lists\n",
    "        Each inner list represents items in a transaction\n",
    "    min_support : float\n",
    "        Minimum support threshold for frequent itemsets (0-1)\n",
    "    min_threshold : float\n",
    "        Minimum lift threshold for association rules\n",
    "    \"\"\"\n",
    "    # Transform transactions to one-hot encoded DataFrame\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MARKET BASKET ANALYSIS - GROCERIES\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal Transactions: {len(transactions)}\")\n",
    "    print(f\"Unique Items: {len(df.columns)}\")\n",
    "    print(f\"\\nTop 10 Item Frequencies:\")\n",
    "    print(df.sum().sort_values(ascending=False).head(10))\n",
    "    \n",
    "    # Generate frequent itemsets\n",
    "    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    print(f\"\\n\\nFrequent Itemsets (support >= {min_support}):\")\n",
    "    print(frequent_itemsets.sort_values('support', ascending=False).to_string())\n",
    "    \n",
    "    # Generate association rules\n",
    "    if len(frequent_itemsets) > 0:\n",
    "        rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_threshold)\n",
    "        rules = rules.sort_values('lift', ascending=False)\n",
    "        \n",
    "        print(f\"\\n\\nAssociation Rules (lift >= {min_threshold}):\")\n",
    "        print(f\"\\nTotal Rules Found: {len(rules)}\")\n",
    "        print(\"\\nTop 15 Rules by Lift:\")\n",
    "        display_cols = ['antecedents', 'consequents', 'support', 'confidence', 'lift']\n",
    "        print(rules[display_cols].head(15).to_string(index=False))\n",
    "        \n",
    "        # Visualizations\n",
    "        create_market_basket_visualizations(rules)\n",
    "        \n",
    "        # Interpretation\n",
    "        print_market_basket_interpretation(rules)\n",
    "        \n",
    "        return rules, frequent_itemsets\n",
    "    else:\n",
    "        print(\"\\nNo frequent itemsets found. Try lowering min_support.\")\n",
    "        return None, frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_market_basket_visualizations(rules):\n",
    "    \"\"\"Create comprehensive market basket analysis visualizations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Lift distribution\n",
    "    axes[0, 0].hist(rules['lift'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0, 0].axvline(x=1, color='red', linestyle='--', linewidth=2, label='Lift = 1 (Independence)')\n",
    "    axes[0, 0].set_xlabel('Lift', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[0, 0].set_title('Distribution of Lift Values', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Support vs Confidence (colored by Lift)\n",
    "    scatter = axes[0, 1].scatter(rules['support'], rules['confidence'], \n",
    "                                  c=rules['lift'], s=100, alpha=0.6, \n",
    "                                  cmap='viridis', edgecolors='black')\n",
    "    axes[0, 1].set_xlabel('Support', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Confidence', fontsize=12)\n",
    "    axes[0, 1].set_title('Support vs Confidence (colored by Lift)', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=axes[0, 1], label='Lift')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Top rules by lift\n",
    "    top_rules = rules.nlargest(10, 'lift')\n",
    "    rule_labels = [f\"{list(ant)[0]} → {list(cons)[0]}\" \n",
    "                   for ant, cons in zip(top_rules['antecedents'], top_rules['consequents'])]\n",
    "    \n",
    "    axes[1, 0].barh(range(len(top_rules)), top_rules['lift'], color='coral', edgecolor='black')\n",
    "    axes[1, 0].set_yticks(range(len(top_rules)))\n",
    "    axes[1, 0].set_yticklabels(rule_labels, fontsize=10)\n",
    "    axes[1, 0].set_xlabel('Lift', fontsize=12)\n",
    "    axes[1, 0].set_title('Top 10 Association Rules by Lift', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].axvline(x=1, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 4. Lift vs Confidence\n",
    "    axes[1, 1].scatter(rules['confidence'], rules['lift'], s=100, alpha=0.6, \n",
    "                       c='darkgreen', edgecolors='black')\n",
    "    axes[1, 1].axhline(y=1, color='red', linestyle='--', linewidth=2, \n",
    "                       label='Lift = 1 (No relationship)', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Confidence', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Lift', fontsize=12)\n",
    "    axes[1, 1].set_title('Confidence vs Lift', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('market_basket_lift_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Visualizations saved as 'market_basket_lift_analysis.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_market_basket_interpretation(rules):\n",
    "    \"\"\"Print interpretation guide for market basket analysis\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"INTERPRETATION GUIDE - MARKET BASKET LIFT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nWhat does Lift mean?\")\n",
    "    print(\"- Lift = 1.0: Items are independent (no relationship)\")\n",
    "    print(\"- Lift > 1.0: Items are positively correlated (bought together more than random)\")\n",
    "    print(\"- Lift < 1.0: Items are negatively correlated (bought together less than random)\")\n",
    "    \n",
    "    if len(rules) > 0:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"EXAMPLE INTERPRETATION\")\n",
    "        print(\"=\" * 80)\n",
    "        top_rule = rules.iloc[0]\n",
    "        ant = list(top_rule['antecedents'])[0]\n",
    "        cons = list(top_rule['consequents'])[0]\n",
    "        lift = top_rule['lift']\n",
    "        conf = top_rule['confidence']\n",
    "        supp = top_rule['support']\n",
    "        \n",
    "        print(f\"\\nRule: {ant} → {cons}\")\n",
    "        print(f\"Lift: {lift:.2f}\")\n",
    "        print(f\"Confidence: {conf:.2%}\")\n",
    "        print(f\"Support: {supp:.2%}\")\n",
    "        print(f\"\\nInterpretation:\")\n",
    "        print(f\"Customers who buy '{ant}' are {lift:.2f}x more likely to buy '{cons}'\")\n",
    "        print(f\"compared to the general population.\")\n",
    "        print(f\"\\n{conf:.1%} of customers who buy '{ant}' also buy '{cons}'.\")\n",
    "        print(f\"This pattern appears in {supp:.1%} of all transactions.\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"BUSINESS RECOMMENDATIONS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\n1. Product Placement: Place '{cons}' near '{ant}' in store\")\n",
    "        print(f\"2. Cross-Selling: Recommend '{cons}' to customers buying '{ant}'\")\n",
    "        print(f\"3. Bundle Offers: Create bundle deals with '{ant}' and '{cons}'\")\n",
    "        print(f\"4. Promotional Strategy: Discount '{ant}' to drive sales of '{cons}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Market Basket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "transactions = load_groceries_data()\n",
    "\n",
    "# Perform analysis\n",
    "# Adjust min_support and min_threshold based on your data\n",
    "rules, frequent_itemsets = perform_market_basket_analysis(\n",
    "    transactions, \n",
    "    min_support=0.15,  # Lower for larger datasets\n",
    "    min_threshold=1.0   # Only show rules with lift > 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Predictive Modeling Lift - Targeting Efficiency\n",
    "\n",
    "## Definition\n",
    "Measures how much better a model is at identifying targets (e.g., churners, buyers) in a specific segment compared to random selection.\n",
    "\n",
    "## Formula\n",
    "$$\\text{Lift} = \\frac{\\% \\text{ of Targets in Segment}}{\\% \\text{ of Population in Segment}}$$\n",
    "\n",
    "## Interpretation\n",
    "If Lift = 3 in the top 10% decile, you capture **3x more targets** than random selection.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_churn_data():\n",
    "    \"\"\"\n",
    "    Load Telco Customer Churn dataset\n",
    "    \n",
    "    For real data, download from:\n",
    "    https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n",
    "    \n",
    "    Expected columns: tenure, MonthlyCharges, TotalCharges, Contract, \n",
    "                     InternetService, TechSupport, PaymentMethod, Churn\n",
    "    \"\"\"\n",
    "    # For demo, create synthetic churn data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 5000\n",
    "    \n",
    "    data = {\n",
    "        'tenure': np.random.randint(0, 72, n_samples),\n",
    "        'MonthlyCharges': np.random.uniform(20, 120, n_samples),\n",
    "        'TotalCharges': np.random.uniform(20, 8000, n_samples),\n",
    "        'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples, p=[0.5, 0.3, 0.2]),\n",
    "        'InternetService': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples, p=[0.35, 0.45, 0.2]),\n",
    "        'TechSupport': np.random.choice(['Yes', 'No'], n_samples),\n",
    "        'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_samples)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Create churn based on logical rules\n",
    "    churn_prob = 0.1 + (df['Contract'] == 'Month-to-month') * 0.3 + \\\n",
    "                 (df['tenure'] < 12) * 0.2 + \\\n",
    "                 (df['MonthlyCharges'] > 80) * 0.15 + \\\n",
    "                 (df['TechSupport'] == 'No') * 0.1\n",
    "    \n",
    "    df['Churn'] = (np.random.random(n_samples) < churn_prob).astype(int)\n",
    "    \n",
    "    # If loading from CSV:\n",
    "    # df = pd.read_csv('telco_churn.csv')\n",
    "    # df['Churn'] = (df['Churn'] == 'Yes').astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lift_curve(y_true, y_pred_proba, n_deciles=10):\n",
    "    \"\"\"\n",
    "    Calculate lift curve for predictive model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True target values (0 or 1)\n",
    "    y_pred_proba : array-like\n",
    "        Predicted probabilities (0 to 1)\n",
    "    n_deciles : int\n",
    "        Number of deciles to divide population into\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with lift metrics per decile\n",
    "    \"\"\"\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    })\n",
    "    \n",
    "    # Sort by predicted probability (descending)\n",
    "    df = df.sort_values('y_pred_proba', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Assign deciles\n",
    "    df['decile'] = pd.qcut(df.index, n_deciles, labels=False, duplicates='drop') + 1\n",
    "    \n",
    "    # Calculate metrics per decile\n",
    "    lift_data = []\n",
    "    cumulative_targets = 0\n",
    "    cumulative_population = 0\n",
    "    total_targets = df['y_true'].sum()\n",
    "    total_population = len(df)\n",
    "    \n",
    "    for decile in range(1, n_deciles + 1):\n",
    "        decile_df = df[df['decile'] == decile]\n",
    "        \n",
    "        # Decile metrics\n",
    "        decile_population = len(decile_df)\n",
    "        decile_targets = decile_df['y_true'].sum()\n",
    "        decile_target_rate = decile_targets / decile_population if decile_population > 0 else 0\n",
    "        \n",
    "        # Cumulative metrics\n",
    "        cumulative_population += decile_population\n",
    "        cumulative_targets += decile_targets\n",
    "        cumulative_target_rate = cumulative_targets / cumulative_population\n",
    "        \n",
    "        # Overall baseline rate\n",
    "        baseline_rate = total_targets / total_population\n",
    "        \n",
    "        # Lift calculations\n",
    "        decile_lift = decile_target_rate / baseline_rate if baseline_rate > 0 else 0\n",
    "        cumulative_lift = cumulative_target_rate / baseline_rate if baseline_rate > 0 else 0\n",
    "        \n",
    "        # % of total targets captured\n",
    "        pct_targets_captured = (cumulative_targets / total_targets) * 100 if total_targets > 0 else 0\n",
    "        pct_population = (cumulative_population / total_population) * 100\n",
    "        \n",
    "        lift_data.append({\n",
    "            'Decile': decile,\n",
    "            'Population': decile_population,\n",
    "            'Targets': int(decile_targets),\n",
    "            'Target_Rate_%': decile_target_rate * 100,\n",
    "            'Decile_Lift': decile_lift,\n",
    "            'Cumulative_Population_%': pct_population,\n",
    "            'Cumulative_Targets': int(cumulative_targets),\n",
    "            'Cumulative_Targets_%': pct_targets_captured,\n",
    "            'Cumulative_Lift': cumulative_lift\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(lift_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lift_analysis(lift_df, model_name=\"Model\"):\n",
    "    \"\"\"Create comprehensive lift analysis visualizations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Decile-wise Lift\n",
    "    axes[0, 0].bar(lift_df['Decile'], lift_df['Decile_Lift'], \n",
    "                   color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axhline(y=1, color='red', linestyle='--', linewidth=2, \n",
    "                       label='Baseline (Random)', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Decile (1 = Highest Predicted Probability)', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Lift', fontsize=12)\n",
    "    axes[0, 0].set_title(f'Decile-wise Lift - {model_name}', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    axes[0, 0].set_xticks(lift_df['Decile'])\n",
    "    \n",
    "    # Add value labels\n",
    "    for idx, row in lift_df.iterrows():\n",
    "        axes[0, 0].text(row['Decile'], row['Decile_Lift'] + 0.1, \n",
    "                        f\"{row['Decile_Lift']:.2f}\", \n",
    "                        ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # 2. Cumulative Lift Curve\n",
    "    axes[0, 1].plot(lift_df['Cumulative_Population_%'], lift_df['Cumulative_Lift'], \n",
    "                    marker='o', linewidth=2, markersize=8, color='darkgreen', label='Model Lift')\n",
    "    axes[0, 1].axhline(y=1, color='red', linestyle='--', linewidth=2, \n",
    "                       label='Random Selection', alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('% of Population Contacted', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Cumulative Lift', fontsize=12)\n",
    "    axes[0, 1].set_title('Cumulative Lift Curve', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_xlim(0, 100)\n",
    "    \n",
    "    # 3. Gains Chart\n",
    "    axes[1, 0].plot(lift_df['Cumulative_Population_%'], lift_df['Cumulative_Targets_%'], \n",
    "                    marker='o', linewidth=2, markersize=8, color='darkorange', label='Model')\n",
    "    axes[1, 0].plot([0, 100], [0, 100], 'r--', linewidth=2, label='Random', alpha=0.7)\n",
    "    axes[1, 0].fill_between(lift_df['Cumulative_Population_%'], \n",
    "                             lift_df['Cumulative_Targets_%'], \n",
    "                             lift_df['Cumulative_Population_%'],\n",
    "                             alpha=0.2, color='darkorange', label='Lift Area')\n",
    "    axes[1, 0].set_xlabel('% of Population Contacted', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('% of Targets Captured', fontsize=12)\n",
    "    axes[1, 0].set_title('Gains Chart (Cumulative)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_xlim(0, 100)\n",
    "    axes[1, 0].set_ylim(0, 100)\n",
    "    \n",
    "    # 4. Target Rate by Decile\n",
    "    axes[1, 1].bar(lift_df['Decile'], lift_df['Target_Rate_%'], \n",
    "                   color='coral', edgecolor='black', alpha=0.7)\n",
    "    baseline_rate = lift_df['Targets'].sum() / lift_df['Population'].sum() * 100\n",
    "    axes[1, 1].axhline(y=baseline_rate, color='red', linestyle='--', linewidth=2, \n",
    "                       label=f'Overall Rate: {baseline_rate:.2f}%', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Decile', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Target Rate (%)', fontsize=12)\n",
    "    axes[1, 1].set_title('Target Rate by Decile', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    axes[1, 1].set_xticks(lift_df['Decile'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filename = f'predictive_lift_{model_name.lower().replace(\" \", \"_\")}.png'\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Visualizations saved as '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_churn_prediction_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform churn prediction and lift analysis\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PREDICTIVE MODELING LIFT - CHURN PREDICTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nDataset Shape: {df.shape}\")\n",
    "    print(f\"Churn Rate: {df['Churn'].mean():.2%}\")\n",
    "    print(f\"\\nChurn Distribution:\")\n",
    "    print(df['Churn'].value_counts())\n",
    "    \n",
    "    # Prepare data\n",
    "    df_encoded = pd.get_dummies(df.drop('Churn', axis=1), drop_first=True)\n",
    "    X = df_encoded\n",
    "    y = df['Churn']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Train models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Training {name}...\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate AUC\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"AUC-ROC: {auc:.4f}\")\n",
    "        \n",
    "        # Calculate lift\n",
    "        lift_df = calculate_lift_curve(y_test, y_pred_proba, n_deciles=10)\n",
    "        \n",
    "        print(f\"\\nLift Table for {name}:\")\n",
    "        print(lift_df.to_string(index=False))\n",
    "        \n",
    "        # Plot\n",
    "        plot_lift_analysis(lift_df, model_name=name)\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'auc': auc,\n",
    "            'lift_df': lift_df,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        # Key insights\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"KEY INSIGHTS - {name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        top_decile = lift_df.iloc[0]\n",
    "        print(f\"\\nTop 10% of Customers (Decile 1):\")\n",
    "        print(f\"  - Lift: {top_decile['Decile_Lift']:.2f}x\")\n",
    "        print(f\"  - Interpretation: By targeting the top 10% highest-risk customers,\")\n",
    "        print(f\"    you capture {top_decile['Decile_Lift']:.2f}x more churners than random selection\")\n",
    "        print(f\"  - Target Rate: {top_decile['Target_Rate_%']:.2f}%\")\n",
    "        print(f\"  - Cumulative Targets Captured: {top_decile['Cumulative_Targets_%']:.1f}%\")\n",
    "    \n",
    "    # Compare models\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': list(results.keys()),\n",
    "        'AUC': [r['auc'] for r in results.values()],\n",
    "        'Top_Decile_Lift': [r['lift_df'].iloc[0]['Decile_Lift'] for r in results.values()],\n",
    "        'Top_30pct_Targets_%': [\n",
    "            r['lift_df'][r['lift_df']['Cumulative_Population_%'] <= 30].iloc[-1]['Cumulative_Targets_%'] \n",
    "            for r in results.values()\n",
    "        ]\n",
    "    })\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Churn Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "churn_df = load_churn_data()\n",
    "\n",
    "# Perform analysis\n",
    "churn_results = perform_churn_prediction_analysis(churn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: A/B Testing Lift - Incremental Impact\n",
    "\n",
    "## Definition\n",
    "The percentage increase in a metric caused by a treatment compared to a control group.\n",
    "\n",
    "## Formula\n",
    "$$\\text{Lift} = \\frac{\\text{Treatment} - \\text{Control}}{\\text{Control}} \\times 100\\%$$\n",
    "\n",
    "## Interpretation\n",
    "- **Positive lift**: Treatment improved the metric\n",
    "- **Negative lift**: Treatment hurt the metric  \n",
    "- **Lift ≈ 0%**: No meaningful difference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ab_test_data():\n",
    "    \"\"\"\n",
    "    Load A/B test dataset\n",
    "    \n",
    "    For real data, download from:\n",
    "    https://www.kaggle.com/datasets/zhangluyuan/ab-testing\n",
    "    \n",
    "    Expected columns: user_id, group (control/treatment), converted (0/1)\n",
    "    \"\"\"\n",
    "    # Create synthetic A/B test data\n",
    "    np.random.seed(42)\n",
    "    n_samples = 10000\n",
    "    \n",
    "    # Control group\n",
    "    control_size = n_samples // 2\n",
    "    control_conversion_rate = 0.12\n",
    "    \n",
    "    # Treatment group\n",
    "    treatment_size = n_samples // 2\n",
    "    treatment_conversion_rate = 0.14  # 16.7% lift\n",
    "    \n",
    "    data = {\n",
    "        'user_id': range(n_samples),\n",
    "        'group': ['control'] * control_size + ['treatment'] * treatment_size,\n",
    "        'converted': (\n",
    "            list(np.random.binomial(1, control_conversion_rate, control_size)) +\n",
    "            list(np.random.binomial(1, treatment_conversion_rate, treatment_size))\n",
    "        ),\n",
    "        'time_on_page_sec': np.concatenate([\n",
    "            np.random.normal(180, 50, control_size),\n",
    "            np.random.normal(200, 50, treatment_size)\n",
    "        ]),\n",
    "        'pages_viewed': np.concatenate([\n",
    "            np.random.poisson(3, control_size),\n",
    "            np.random.poisson(3.5, treatment_size)\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # If loading from CSV:\n",
    "    # df = pd.read_csv('ab_test_data.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ab_lift(control_metric, treatment_metric):\n",
    "    \"\"\"Calculate lift from A/B test\"\"\"\n",
    "    lift = ((treatment_metric - control_metric) / control_metric) * 100\n",
    "    return lift\n",
    "\n",
    "def perform_statistical_test(control_data, treatment_data, metric_name=\"Conversion\"):\n",
    "    \"\"\"Perform statistical significance test\"\"\"\n",
    "    if metric_name == \"Conversion\":\n",
    "        # For binary outcomes, use proportions z-test\n",
    "        from statsmodels.stats.proportion import proportions_ztest\n",
    "        \n",
    "        count = np.array([treatment_data.sum(), control_data.sum()])\n",
    "        nobs = np.array([len(treatment_data), len(control_data)])\n",
    "        \n",
    "        stat, pval = proportions_ztest(count, nobs)\n",
    "        test_name = \"Proportions Z-Test\"\n",
    "    else:\n",
    "        # For continuous metrics, use t-test\n",
    "        stat, pval = stats.ttest_ind(treatment_data, control_data)\n",
    "        test_name = \"Independent T-Test\"\n",
    "    \n",
    "    return stat, pval, test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ab_test_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform comprehensive A/B test analysis with lift calculations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"A/B TESTING LIFT - CONVERSION OPTIMIZATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Split data\n",
    "    control = df[df['group'] == 'control']\n",
    "    treatment = df[df['group'] == 'treatment']\n",
    "    \n",
    "    print(f\"\\nSample Sizes:\")\n",
    "    print(f\"  Control: {len(control):,}\")\n",
    "    print(f\"  Treatment: {len(treatment):,}\")\n",
    "    \n",
    "    # Define metrics\n",
    "    metrics = {\n",
    "        'Conversion Rate': ('converted', 'mean'),\n",
    "        'Avg Time on Page (sec)': ('time_on_page_sec', 'mean'),\n",
    "        'Avg Pages Viewed': ('pages_viewed', 'mean')\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for metric_name, (column, agg_func) in metrics.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"METRIC: {metric_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        control_metric = control[column].mean()\n",
    "        treatment_metric = treatment[column].mean()\n",
    "        control_std = control[column].std()\n",
    "        treatment_std = treatment[column].std()\n",
    "        \n",
    "        # Calculate lift\n",
    "        lift = calculate_ab_lift(control_metric, treatment_metric)\n",
    "        \n",
    "        # Statistical test\n",
    "        stat, pval, test_name = perform_statistical_test(\n",
    "            control[column], treatment[column], \n",
    "            metric_name=\"Conversion\" if column == 'converted' else \"Other\"\n",
    "        )\n",
    "        \n",
    "        # Bootstrap confidence interval\n",
    "        n_bootstrap = 1000\n",
    "        bootstrap_lifts = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            c_sample = control[column].sample(len(control), replace=True).mean()\n",
    "            t_sample = treatment[column].sample(len(treatment), replace=True).mean()\n",
    "            bootstrap_lifts.append(calculate_ab_lift(c_sample, t_sample))\n",
    "        \n",
    "        ci_lower = np.percentile(bootstrap_lifts, 2.5)\n",
    "        ci_upper = np.percentile(bootstrap_lifts, 97.5)\n",
    "        \n",
    "        # Print results\n",
    "        if 'Rate' in metric_name:\n",
    "            print(f\"\\nControl:    {control_metric:.2%} (n={len(control):,})\")\n",
    "            print(f\"Treatment:  {treatment_metric:.2%} (n={len(treatment):,})\")\n",
    "        else:\n",
    "            print(f\"\\nControl:    {control_metric:.2f} ± {control_std:.2f} (n={len(control):,})\")\n",
    "            print(f\"Treatment:  {treatment_metric:.2f} ± {treatment_std:.2f} (n={len(treatment):,})\")\n",
    "        \n",
    "        print(f\"\\nLIFT: {lift:+.2f}%\")\n",
    "        print(f\"95% CI: [{ci_lower:+.2f}%, {ci_upper:+.2f}%]\")\n",
    "        print(f\"\\n{test_name}:\")\n",
    "        print(f\"  Test Statistic: {stat:.4f}\")\n",
    "        print(f\"  P-value: {pval:.4f}\")\n",
    "        \n",
    "        is_significant = pval < 0.05\n",
    "        print(f\"  Result: {'SIGNIFICANT' if is_significant else 'NOT SIGNIFICANT'} (α=0.05)\")\n",
    "        \n",
    "        if is_significant:\n",
    "            direction = \"increase\" if lift > 0 else \"decrease\"\n",
    "            print(f\"\\n✓ The treatment caused a statistically significant {direction}\")\n",
    "            print(f\"  of {abs(lift):.2f}% in {metric_name}\")\n",
    "        else:\n",
    "            print(f\"\\n✗ No statistically significant difference detected\")\n",
    "        \n",
    "        results.append({\n",
    "            'Metric': metric_name,\n",
    "            'Control': control_metric,\n",
    "            'Treatment': treatment_metric,\n",
    "            'Lift_%': lift,\n",
    "            'CI_Lower_%': ci_lower,\n",
    "            'CI_Upper_%': ci_upper,\n",
    "            'P_value': pval,\n",
    "            'Significant': is_significant\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_ab_test_visualizations(results_df, control, treatment)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY TABLE - ALL METRICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    print_ab_test_interpretation()\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ab_test_visualizations(results_df, control, treatment):\n",
    "    \"\"\"Create A/B test visualizations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Lift by Metric\n",
    "    colors = ['green' if s else 'red' for s in results_df['Significant']]\n",
    "    axes[0, 0].barh(results_df['Metric'], results_df['Lift_%'], \n",
    "                    color=colors, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    axes[0, 0].set_xlabel('Lift (%)', fontsize=12)\n",
    "    axes[0, 0].set_title('A/B Test Lift by Metric', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    for i, row in results_df.iterrows():\n",
    "        axes[0, 0].text(row['Lift_%'], i, f\"  {row['Lift_%']:+.2f}%  \", \n",
    "                        ha='left' if row['Lift_%'] > 0 else 'right', \n",
    "                        va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # 2. Lift with Confidence Intervals\n",
    "    axes[0, 1].barh(results_df['Metric'], results_df['Lift_%'], \n",
    "                    color=colors, edgecolor='black', alpha=0.7)\n",
    "    \n",
    "    for i, row in results_df.iterrows():\n",
    "        axes[0, 1].plot([row['CI_Lower_%'], row['CI_Upper_%']], [i, i], \n",
    "                        'k-', linewidth=2, marker='|', markersize=10)\n",
    "    \n",
    "    axes[0, 1].axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    axes[0, 1].set_xlabel('Lift (%) with 95% CI', fontsize=12)\n",
    "    axes[0, 1].set_title('Lift with Confidence Intervals', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 3. Conversion Rate Comparison\n",
    "    conv_row = results_df[results_df['Metric'].str.contains('Conversion')].iloc[0]\n",
    "    x = np.arange(2)\n",
    "    values = [conv_row['Control'], conv_row['Treatment']]\n",
    "    \n",
    "    bars = axes[1, 0].bar(x, [v * 100 for v in values], \n",
    "                          color=['steelblue', 'coral'], edgecolor='black', alpha=0.7, width=0.5)\n",
    "    axes[1, 0].set_ylabel('Conversion Rate (%)', fontsize=12)\n",
    "    axes[1, 0].set_title('Conversion Rate: Control vs Treatment', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(['Control', 'Treatment'])\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar, val in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{val*100:.2f}%', ha='center', va='bottom', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 4. Statistical Significance Summary\n",
    "    sig_counts = results_df['Significant'].value_counts()\n",
    "    colors_pie = ['green', 'red']\n",
    "    labels = ['Significant', 'Not Significant']\n",
    "    \n",
    "    wedges, texts, autotexts = axes[1, 1].pie(\n",
    "        [sig_counts.get(True, 0), sig_counts.get(False, 0)],\n",
    "        labels=labels, colors=colors_pie, autopct='%1.0f%%',\n",
    "        startangle=90, explode=[0.05, 0]\n",
    "    )\n",
    "    \n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontsize(12)\n",
    "        autotext.set_fontweight('bold')\n",
    "    \n",
    "    axes[1, 1].set_title('Statistical Significance Summary', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ab_test_lift_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Visualizations saved as 'ab_test_lift_analysis.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ab_test_interpretation():\n",
    "    \"\"\"Print interpretation guide for A/B testing\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"INTERPRETATION GUIDE - A/B TEST LIFT\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nWhat does Lift mean in A/B Testing?\")\n",
    "    print(\"- Lift shows the % change in a metric caused by the treatment\")\n",
    "    print(\"- Positive lift = Treatment improved the metric\")\n",
    "    print(\"- Negative lift = Treatment hurt the metric\")\n",
    "    print(\"- Lift near 0% = No meaningful difference\")\n",
    "    print(\"\\nStatistical Significance:\")\n",
    "    print(\"- P-value < 0.05: We can be confident the difference is real\")\n",
    "    print(\"- P-value >= 0.05: Difference might be due to chance\")\n",
    "    print(\"\\nConfidence Intervals:\")\n",
    "    print(\"- If CI doesn't cross 0%, the effect is statistically significant\")\n",
    "    print(\"- Wider CI = More uncertainty in the estimate\")\n",
    "    print(\"\\nBusiness Decision:\")\n",
    "    print(\"- Roll out treatment if: Positive lift AND p-value < 0.05\")\n",
    "    print(\"- Don't roll out if: Negative lift OR not significant\")\n",
    "    print(\"- Consider costs: Small lift may not justify implementation costs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run A/B Test Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ab_test_df = load_ab_test_data()\n",
    "\n",
    "# Perform analysis\n",
    "ab_results = perform_ab_test_analysis(ab_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary: Comparing All Three Lift Types\n",
    "\n",
    "## Quick Reference Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lift_comparison_summary():\n",
    "    \"\"\"Create comprehensive comparison of all three lift types\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"COMPREHENSIVE LIFT ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    summary_data = {\n",
    "        'Lift Type': [\n",
    "            'Market Basket\\n(Association)',\n",
    "            'Predictive Model\\n(Targeting)',\n",
    "            'A/B Testing\\n(Incremental)'\n",
    "        ],\n",
    "        'Question Answered': [\n",
    "            'What products are\\nbought together?',\n",
    "            'How well can I\\nidentify targets?',\n",
    "            'Did my change\\nimprove the metric?'\n",
    "        ],\n",
    "        'Formula': [\n",
    "            'P(A∩B) /\\n[P(A)×P(B)]',\n",
    "            '% Targets /\\n% Population',\n",
    "            '(Treat - Ctrl) /\\nCtrl × 100%'\n",
    "        ],\n",
    "        'Baseline': [\n",
    "            'Independence\\n(Lift = 1)',\n",
    "            'Random\\n(Lift = 1)',\n",
    "            'Control\\n(Lift = 0%)'\n",
    "        ],\n",
    "        'Use Case': [\n",
    "            'Cross-selling,\\nProduct placement',\n",
    "            'Campaign targeting,\\nChurn prevention',\n",
    "            'Feature testing,\\nUI/UX changes'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KEY TAKEAWAYS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\"\"\n",
    "1. MARKET BASKET LIFT (Association Rules)\n",
    "   - Answers: \"What products are bought together?\"\n",
    "   - Action: Place related items near each other, create bundles\n",
    "   - Success: Lift > 1 means positive association\n",
    "\n",
    "2. PREDICTIVE MODEL LIFT (Targeting Efficiency)\n",
    "   - Answers: \"How well can I identify high-value customers?\"\n",
    "   - Action: Target top deciles for campaigns to maximize ROI\n",
    "   - Success: High lift in top deciles = efficient targeting\n",
    "\n",
    "3. A/B TEST LIFT (Incremental Impact)\n",
    "   - Answers: \"Did my change actually improve the metric?\"\n",
    "   - Action: Roll out treatment if lift is positive and significant\n",
    "   - Success: Positive lift with p-value < 0.05\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # 1. Market Basket\n",
    "    rules_example = ['Milk→Bread', 'Beer→Diapers', 'Wine→Cheese', 'Coffee→Sugar']\n",
    "    lifts_example = [2.1, 3.5, 2.8, 1.9]\n",
    "    axes[0].barh(rules_example, lifts_example, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0].axvline(x=1, color='red', linestyle='--', linewidth=2, label='Independence')\n",
    "    axes[0].set_xlabel('Lift (Association Strength)', fontsize=11)\n",
    "    axes[0].set_title('Market Basket Lift\\n(Product Associations)', fontsize=13, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 2. Predictive Model\n",
    "    deciles = list(range(1, 11))\n",
    "    model_lifts = [4.2, 3.1, 2.5, 2.0, 1.6, 1.3, 1.0, 0.8, 0.6, 0.4]\n",
    "    axes[1].plot(deciles, model_lifts, marker='o', linewidth=2, markersize=8, \n",
    "                 color='darkgreen', label='Model')\n",
    "    axes[1].axhline(y=1, color='red', linestyle='--', linewidth=2, label='Random')\n",
    "    axes[1].set_xlabel('Decile (1 = Highest Risk)', fontsize=11)\n",
    "    axes[1].set_ylabel('Lift', fontsize=11)\n",
    "    axes[1].set_title('Predictive Model Lift\\n(Targeting Efficiency)', fontsize=13, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_xticks(deciles)\n",
    "    \n",
    "    # 3. A/B Test\n",
    "    metrics_ab = ['Conversion\\nRate', 'Time on\\nPage', 'Pages\\nViewed']\n",
    "    lifts_ab = [16.7, 11.1, 8.3]\n",
    "    colors = ['green', 'green', 'coral']\n",
    "    axes[2].bar(metrics_ab, lifts_ab, color=colors, edgecolor='black', alpha=0.7)\n",
    "    axes[2].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    axes[2].set_ylabel('Lift (%)', fontsize=11)\n",
    "    axes[2].set_title('A/B Test Lift\\n(Incremental Impact)', fontsize=13, fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for i, (metric, lift) in enumerate(zip(metrics_ab, lifts_ab)):\n",
    "        axes[2].text(i, lift + 1, f'{lift:+.1f}%', \n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lift_types_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Comparison visualization saved as 'lift_types_comparison.png'\")\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Create summary\n",
    "summary_df = create_lift_comparison_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. MARKET BASKET ANALYSIS\n",
    "   → Implement: Use high-lift rules for product recommendations\n",
    "   → Monitor: Track conversion rates on recommended bundles\n",
    "   → Iterate: Update rules quarterly with fresh transaction data\n",
    "\n",
    "2. PREDICTIVE MODELING\n",
    "   → Implement: Target top 2-3 deciles for retention campaigns\n",
    "   → Monitor: Track actual churn rate in targeted segments\n",
    "   → Iterate: Retrain models monthly with new outcomes\n",
    "\n",
    "3. A/B TESTING\n",
    "   → Implement: Roll out significant positive lifts gradually\n",
    "   → Monitor: Track metrics over extended period\n",
    "   → Iterate: Run follow-up tests to optimize further\n",
    "\n",
    "GENERAL BEST PRACTICES:\n",
    "- Always compare lift to a baseline (random/control)\n",
    "- Use statistical tests to validate findings\n",
    "- Document assumptions and limitations\n",
    "- Combine multiple lift analyses for holistic insights\n",
    "- Consider business context and implementation costs\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILES GENERATED\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. market_basket_lift_analysis.png - Association rules visualization\n",
    "2. predictive_lift_*.png - Model targeting efficiency charts\n",
    "3. ab_test_lift_analysis.png - A/B test results\n",
    "4. lift_types_comparison.png - Side-by-side comparison\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
