{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Basket Analysis - Association Rule Lift\n",
    "\n",
    "## Definition\n",
    "Measures how much more likely a customer is to buy **Item B** given they bought **Item A**, compared to buying B randomly.\n",
    "\n",
    "## Formula\n",
    "$$\\text{Lift} = \\frac{P(A \\cap B)}{P(A) \\times P(B)}$$\n",
    "\n",
    "Where:\n",
    "- P(A ∩ B) = Probability of buying both A and B together\n",
    "- P(A) = Probability of buying A\n",
    "- P(B) = Probability of buying B\n",
    "\n",
    "## Interpretation\n",
    "- **Lift = 1.0**: Items are independent (no relationship)\n",
    "- **Lift > 1.0**: Items are positively correlated (bought together more than random)\n",
    "- **Lift < 1.0**: Items are negatively correlated (bought together less than random)\n",
    "\n",
    "## Use Cases\n",
    "- Product placement in stores\n",
    "- Cross-selling recommendations\n",
    "- Bundle creation\n",
    "- Promotional strategies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install pandas numpy matplotlib seaborn mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "**For real data**: Download from https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset\n",
    "\n",
    "Expected format: List of transactions where each transaction is a list of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_groceries_data():\n",
    "    \"\"\"\n",
    "    Load groceries transaction data\n",
    "    \n",
    "    For CSV format:\n",
    "    df = pd.read_csv('groceries.csv')\n",
    "    transactions = df.groupby('Member_number')['itemDescription'].apply(list).tolist()\n",
    "    \"\"\"\n",
    "    # Sample data for demonstration\n",
    "    transactions = [\n",
    "        ['milk', 'bread', 'butter'],\n",
    "        ['beer', 'diapers', 'bread'],\n",
    "        ['milk', 'bread', 'butter', 'cheese'],\n",
    "        ['beer', 'diapers'],\n",
    "        ['milk', 'bread', 'butter', 'eggs'],\n",
    "        ['beer', 'diapers', 'chips'],\n",
    "        ['milk', 'cheese'],\n",
    "        ['bread', 'butter', 'eggs'],\n",
    "        ['beer', 'diapers', 'bread', 'chips'],\n",
    "        ['milk', 'bread', 'cheese', 'eggs'],\n",
    "        ['coffee', 'sugar', 'milk'],\n",
    "        ['wine', 'cheese', 'crackers'],\n",
    "        ['beer', 'chips', 'salsa'],\n",
    "        ['pasta', 'tomato sauce', 'cheese'],\n",
    "        ['chicken', 'rice', 'vegetables'],\n",
    "        ['milk', 'bread', 'eggs'],\n",
    "        ['beer', 'diapers', 'wipes'],\n",
    "        ['wine', 'cheese'],\n",
    "        ['coffee', 'creamer', 'sugar'],\n",
    "        ['bread', 'butter', 'jam'],\n",
    "    ]\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "# Load data\n",
    "transactions = load_groceries_data()\n",
    "print(f\"Loaded {len(transactions)} transactions\")\n",
    "print(f\"\\nSample transactions:\")\n",
    "for i, trans in enumerate(transactions[:5], 1):\n",
    "    print(f\"  {i}. {trans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Market Basket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_market_basket_analysis(transactions, min_support=0.15, min_threshold=1.0):\n",
    "    \"\"\"\n",
    "    Perform market basket analysis and calculate lift\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    transactions : list of lists\n",
    "        Each inner list contains items in a transaction\n",
    "    min_support : float (0-1)\n",
    "        Minimum support threshold for frequent itemsets\n",
    "        Lower values find more patterns but may be less meaningful\n",
    "    min_threshold : float\n",
    "        Minimum lift threshold for association rules\n",
    "        1.0 means only show positive associations\n",
    "    \"\"\"\n",
    "    # Transform to one-hot encoded DataFrame\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MARKET BASKET ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal Transactions: {len(transactions)}\")\n",
    "    print(f\"Unique Items: {len(df.columns)}\")\n",
    "    \n",
    "    # Item frequencies\n",
    "    print(f\"\\nTop 10 Most Frequent Items:\")\n",
    "    item_freq = df.sum().sort_values(ascending=False)\n",
    "    print(item_freq.head(10).to_string())\n",
    "    \n",
    "    # Generate frequent itemsets\n",
    "    print(f\"\\n\\nFinding frequent itemsets (min_support={min_support})...\")\n",
    "    frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "    print(f\"Found {len(frequent_itemsets)} frequent itemsets\")\n",
    "    \n",
    "    if len(frequent_itemsets) == 0:\n",
    "        print(\"\\n⚠ No frequent itemsets found. Try lowering min_support.\")\n",
    "        return None, None\n",
    "    \n",
    "    print(\"\\nTop 15 Frequent Itemsets:\")\n",
    "    print(frequent_itemsets.sort_values('support', ascending=False).head(15).to_string())\n",
    "    \n",
    "    # Generate association rules\n",
    "    print(f\"\\n\\nGenerating association rules (min_lift={min_threshold})...\")\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=min_threshold)\n",
    "    rules = rules.sort_values('lift', ascending=False)\n",
    "    \n",
    "    print(f\"Found {len(rules)} association rules\")\n",
    "    \n",
    "    if len(rules) == 0:\n",
    "        print(\"\\n⚠ No rules found. Try lowering min_threshold or min_support.\")\n",
    "        return None, frequent_itemsets\n",
    "    \n",
    "    print(\"\\nTop 20 Association Rules by Lift:\")\n",
    "    display_cols = ['antecedents', 'consequents', 'support', 'confidence', 'lift']\n",
    "    print(rules[display_cols].head(20).to_string(index=False))\n",
    "    \n",
    "    return rules, frequent_itemsets\n",
    "\n",
    "# Perform analysis\n",
    "rules, frequent_itemsets = perform_market_basket_analysis(\n",
    "    transactions, \n",
    "    min_support=0.15,  # Adjust based on your data size\n",
    "    min_threshold=1.0   # Only show positive associations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(rules):\n",
    "    \"\"\"Create comprehensive market basket analysis visualizations\"\"\"\n",
    "    \n",
    "    if rules is None or len(rules) == 0:\n",
    "        print(\"No rules to visualize\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Lift Distribution\n",
    "    axes[0, 0].hist(rules['lift'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0, 0].axvline(x=1, color='red', linestyle='--', linewidth=2, \n",
    "                       label='Lift = 1 (Independence)', alpha=0.8)\n",
    "    axes[0, 0].set_xlabel('Lift', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_title('Distribution of Lift Values', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend(fontsize=10)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Support vs Confidence (colored by Lift)\n",
    "    scatter = axes[0, 1].scatter(rules['support'], rules['confidence'], \n",
    "                                  c=rules['lift'], s=100, alpha=0.6, \n",
    "                                  cmap='viridis', edgecolors='black', linewidths=1)\n",
    "    axes[0, 1].set_xlabel('Support', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Confidence', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_title('Support vs Confidence (colored by Lift)', \n",
    "                         fontsize=14, fontweight='bold')\n",
    "    cbar = plt.colorbar(scatter, ax=axes[0, 1])\n",
    "    cbar.set_label('Lift', fontsize=11, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Top Rules by Lift\n",
    "    top_rules = rules.nlargest(min(10, len(rules)), 'lift')\n",
    "    rule_labels = [f\"{list(ant)[0]} → {list(cons)[0]}\" \n",
    "                   for ant, cons in zip(top_rules['antecedents'], top_rules['consequents'])]\n",
    "    \n",
    "    y_pos = np.arange(len(top_rules))\n",
    "    axes[1, 0].barh(y_pos, top_rules['lift'], color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_yticks(y_pos)\n",
    "    axes[1, 0].set_yticklabels(rule_labels, fontsize=10)\n",
    "    axes[1, 0].set_xlabel('Lift', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_title('Top 10 Association Rules by Lift', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].axvline(x=1, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "    axes[1, 0].invert_yaxis()\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (idx, row) in enumerate(top_rules.iterrows()):\n",
    "        axes[1, 0].text(row['lift'] + 0.05, i, f\"{row['lift']:.2f}\", \n",
    "                        va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # 4. Lift vs Confidence\n",
    "    axes[1, 1].scatter(rules['confidence'], rules['lift'], s=100, alpha=0.6, \n",
    "                       c='darkgreen', edgecolors='black', linewidths=1)\n",
    "    axes[1, 1].axhline(y=1, color='red', linestyle='--', linewidth=2, \n",
    "                       label='Lift = 1 (No relationship)', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Confidence', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Lift', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_title('Confidence vs Lift', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].legend(fontsize=10)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('market_basket_lift_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Visualizations saved as 'market_basket_lift_analysis.png'\")\n",
    "\n",
    "# Create visualizations\n",
    "if rules is not None:\n",
    "    create_visualizations(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_business_insights(rules):\n",
    "    \"\"\"Print detailed interpretation and business recommendations\"\"\"\n",
    "    \n",
    "    if rules is None or len(rules) == 0:\n",
    "        print(\"No rules to interpret\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"UNDERSTANDING LIFT IN MARKET BASKET ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\"\"\n",
    "Lift measures the strength of association between items:\n",
    "\n",
    "• Lift = 1.0: Items are independent (no relationship)\n",
    "  - Buying Item A doesn't affect likelihood of buying Item B\n",
    "\n",
    "• Lift > 1.0: Positive correlation (items bought together)\n",
    "  - Lift = 2.0 means customers are 2x more likely to buy B when they buy A\n",
    "  - Lift = 3.5 means customers are 3.5x more likely\n",
    "\n",
    "• Lift < 1.0: Negative correlation (items bought apart)\n",
    "  - Customers who buy A are less likely to buy B\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DETAILED EXAMPLE - TOP RULE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    top_rule = rules.iloc[0]\n",
    "    ant = list(top_rule['antecedents'])[0]\n",
    "    cons = list(top_rule['consequents'])[0]\n",
    "    lift = top_rule['lift']\n",
    "    conf = top_rule['confidence']\n",
    "    supp = top_rule['support']\n",
    "    \n",
    "    print(f\"\\nRule: {ant} → {cons}\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  • Lift:       {lift:.2f}\")\n",
    "    print(f\"  • Confidence: {conf:.2%}\")\n",
    "    print(f\"  • Support:    {supp:.2%}\")\n",
    "    \n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"  Customers who buy '{ant}' are {lift:.2f}x more likely to buy '{cons}'\")\n",
    "    print(f\"  compared to customers in general.\")\n",
    "    print(f\"\\n  Specifically:\")\n",
    "    print(f\"  • {conf:.1%} of customers who buy '{ant}' also buy '{cons}'\")\n",
    "    print(f\"  • This pattern appears in {supp:.1%} of all transactions\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BUSINESS RECOMMENDATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\"\"\n",
    "Based on the top rule ({ant} → {cons}):\n",
    "\n",
    "1. PRODUCT PLACEMENT\n",
    "   • Place '{cons}' near '{ant}' in store layout\n",
    "   • Ensure both items are easily accessible together\n",
    "\n",
    "2. CROSS-SELLING STRATEGY\n",
    "   • When customer adds '{ant}' to cart, recommend '{cons}'\n",
    "   • Train staff to suggest '{cons}' when '{ant}' is purchased\n",
    "\n",
    "3. BUNDLE OFFERS\n",
    "   • Create bundle: '{ant}' + '{cons}' at discounted price\n",
    "   • Expected lift: {lift:.2f}x higher purchase rate\n",
    "\n",
    "4. PROMOTIONAL STRATEGY\n",
    "   • Discount '{ant}' to drive traffic → increase '{cons}' sales\n",
    "   • Run \"Buy '{ant}', get discount on '{cons}'\" promotion\n",
    "\n",
    "5. INVENTORY MANAGEMENT\n",
    "   • Maintain proportional stock levels\n",
    "   • If '{ant}' sells well, ensure '{cons}' is in stock\n",
    "    \"\"\")\n",
    "    \n",
    "    # Additional high-lift rules\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OTHER HIGH-LIFT OPPORTUNITIES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    top_5 = rules.head(5)\n",
    "    for i, (idx, row) in enumerate(top_5.iterrows(), 1):\n",
    "        ant = list(row['antecedents'])[0]\n",
    "        cons = list(row['consequents'])[0]\n",
    "        print(f\"\\n{i}. {ant} → {cons}\")\n",
    "        print(f\"   Lift: {row['lift']:.2f}x | Confidence: {row['confidence']:.1%} | Support: {row['support']:.1%}\")\n",
    "\n",
    "# Print insights\n",
    "if rules is not None:\n",
    "    print_business_insights(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Rules to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rules is not None and len(rules) > 0:\n",
    "    # Prepare export with readable format\n",
    "    export_df = rules.copy()\n",
    "    export_df['antecedents'] = export_df['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "    export_df['consequents'] = export_df['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "    \n",
    "    # Select relevant columns\n",
    "    export_cols = ['antecedents', 'consequents', 'support', 'confidence', 'lift']\n",
    "    export_df = export_df[export_cols]\n",
    "    \n",
    "    # Save to CSV\n",
    "    export_df.to_csv('market_basket_rules.csv', index=False)\n",
    "    print(\"\\n✓ Rules exported to 'market_basket_rules.csv'\")\n",
    "    print(f\"  Total rules exported: {len(export_df)}\")\n",
    "else:\n",
    "    print(\"\\nNo rules to export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Filter Rules by Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rules is not None and len(rules) > 0:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FILTERING RULES BY CRITERIA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # High-impact rules: High lift AND high confidence\n",
    "    high_impact = rules[(rules['lift'] > 2.0) & (rules['confidence'] > 0.5)]\n",
    "    print(f\"\\nHigh-Impact Rules (Lift > 2.0 AND Confidence > 50%):\")\n",
    "    print(f\"Found {len(high_impact)} rules\")\n",
    "    if len(high_impact) > 0:\n",
    "        display_cols = ['antecedents', 'consequents', 'lift', 'confidence', 'support']\n",
    "        print(high_impact[display_cols].head(10).to_string(index=False))\n",
    "    \n",
    "    # Frequent AND strong rules\n",
    "    frequent_strong = rules[(rules['support'] > 0.1) & (rules['lift'] > 1.5)]\n",
    "    print(f\"\\n\\nFrequent & Strong Rules (Support > 10% AND Lift > 1.5):\")\n",
    "    print(f\"Found {len(frequent_strong)} rules\")\n",
    "    if len(frequent_strong) > 0:\n",
    "        print(frequent_strong[display_cols].head(10).to_string(index=False))\n",
    "    \n",
    "    # Rules for specific product\n",
    "    target_product = 'milk'  # Change this to any product in your data\n",
    "    product_rules = rules[\n",
    "        rules['antecedents'].apply(lambda x: target_product in [str(i).lower() for i in x]) |\n",
    "        rules['consequents'].apply(lambda x: target_product in [str(i).lower() for i in x])\n",
    "    ]\n",
    "    print(f\"\\n\\nRules involving '{target_product}':\")\n",
    "    print(f\"Found {len(product_rules)} rules\")\n",
    "    if len(product_rules) > 0:\n",
    "        print(product_rules[display_cols].head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo rules available for filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rules is not None and len(rules) > 0:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nTotal Rules Found: {len(rules)}\")\n",
    "    print(f\"\\nLift Statistics:\")\n",
    "    print(f\"  Mean:   {rules['lift'].mean():.2f}\")\n",
    "    print(f\"  Median: {rules['lift'].median():.2f}\")\n",
    "    print(f\"  Min:    {rules['lift'].min():.2f}\")\n",
    "    print(f\"  Max:    {rules['lift'].max():.2f}\")\n",
    "    print(f\"  Std:    {rules['lift'].std():.2f}\")\n",
    "    \n",
    "    print(f\"\\nConfidence Statistics:\")\n",
    "    print(f\"  Mean:   {rules['confidence'].mean():.2%}\")\n",
    "    print(f\"  Median: {rules['confidence'].median():.2%}\")\n",
    "    print(f\"  Min:    {rules['confidence'].min():.2%}\")\n",
    "    print(f\"  Max:    {rules['confidence'].max():.2%}\")\n",
    "    \n",
    "    print(f\"\\nSupport Statistics:\")\n",
    "    print(f\"  Mean:   {rules['support'].mean():.2%}\")\n",
    "    print(f\"  Median: {rules['support'].median():.2%}\")\n",
    "    print(f\"  Min:    {rules['support'].min():.2%}\")\n",
    "    print(f\"  Max:    {rules['support'].max():.2%}\")\n",
    "    \n",
    "    print(f\"\\nRules by Lift Category:\")\n",
    "    print(f\"  Very Strong (Lift > 3.0):     {len(rules[rules['lift'] > 3.0])} rules\")\n",
    "    print(f\"  Strong (2.0 < Lift ≤ 3.0):    {len(rules[(rules['lift'] > 2.0) & (rules['lift'] <= 3.0)])} rules\")\n",
    "    print(f\"  Moderate (1.5 < Lift ≤ 2.0):  {len(rules[(rules['lift'] > 1.5) & (rules['lift'] <= 2.0)])} rules\")\n",
    "    print(f\"  Weak (1.0 < Lift ≤ 1.5):      {len(rules[(rules['lift'] > 1.0) & (rules['lift'] <= 1.5)])} rules\")\n",
    "else:\n",
    "    print(\"\\nNo rules available for summary statistics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
