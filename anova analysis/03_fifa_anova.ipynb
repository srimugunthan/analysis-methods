{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA Analysis: FIFA Player Ratings by Position\n",
    "\n",
    "## Research Question\n",
    "**Is there a significant difference in average 'Overall Rating' across different field positions?**\n",
    "\n",
    "### Dataset Overview\n",
    "- **Source**: Kaggle - FIFA 23 Dataset\n",
    "- **Description**: Overall ratings of thousands of football players\n",
    "- **Groups**: Player positions (Attacker, Midfielder, Defender, Goalkeeper)\n",
    "- **Dependent Variable**: Overall Rating (continuous, 0-100 scale)\n",
    "- **Independent Variable**: Player position (categorical)\n",
    "\n",
    "### Alternative Analysis\n",
    "We can also examine: Preferred Foot (Left vs. Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway, shapiro, levene, kruskal, mannwhitneyu\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.formula.api import ols\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load FIFA Dataset\n",
    "\n",
    "Note: Since we cannot directly download from Kaggle without authentication, we'll create a realistic sample dataset based on typical FIFA ratings patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create realistic FIFA player data\n",
    "print(\"Creating representative FIFA player dataset...\\n\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Realistic distributions based on FIFA ratings patterns\n",
    "# Attackers typically have slightly higher overall ratings\n",
    "n_attackers = 300\n",
    "n_midfielders = 350\n",
    "n_defenders = 300\n",
    "n_goalkeepers = 150\n",
    "\n",
    "# Generate ratings with position-specific characteristics\n",
    "# Attackers: mean ~72, SD ~8\n",
    "attackers = np.clip(np.random.normal(72, 8, n_attackers), 45, 94)\n",
    "\n",
    "# Midfielders: mean ~71, SD ~7.5\n",
    "midfielders = np.clip(np.random.normal(71, 7.5, n_midfielders), 45, 93)\n",
    "\n",
    "# Defenders: mean ~70, SD ~7\n",
    "defenders = np.clip(np.random.normal(70, 7, n_defenders), 45, 92)\n",
    "\n",
    "# Goalkeepers: mean ~69, SD ~8 (more variable)\n",
    "goalkeepers = np.clip(np.random.normal(69, 8, n_goalkeepers), 45, 91)\n",
    "\n",
    "# Create position labels\n",
    "positions = (['Attacker'] * n_attackers + \n",
    "             ['Midfielder'] * n_midfielders + \n",
    "             ['Defender'] * n_defenders + \n",
    "             ['Goalkeeper'] * n_goalkeepers)\n",
    "\n",
    "# Generate preferred foot (roughly 75% right, 25% left)\n",
    "total_players = n_attackers + n_midfielders + n_defenders + n_goalkeepers\n",
    "preferred_foot = np.random.choice(['Right', 'Left'], \n",
    "                                  size=total_players, \n",
    "                                  p=[0.75, 0.25])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'player_id': range(1, total_players + 1),\n",
    "    'overall_rating': np.concatenate([attackers, midfielders, defenders, goalkeepers]),\n",
    "    'position': positions,\n",
    "    'preferred_foot': preferred_foot\n",
    "})\n",
    "\n",
    "# Add player names (generic)\n",
    "df['player_name'] = [f'Player_{i}' for i in range(1, total_players + 1)]\n",
    "\n",
    "# Round ratings to integers\n",
    "df['overall_rating'] = df['overall_rating'].round().astype(int)\n",
    "\n",
    "print(f\"✓ Dataset created with {len(df)} players\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nFirst 10 players:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Position Distribution:\")\n",
    "print(df['position'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Preferred Foot Distribution:\")\n",
    "print(df['preferred_foot'].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Overall Rating Range:\")\n",
    "print(f\"Minimum: {df['overall_rating'].min()}\")\n",
    "print(f\"Maximum: {df['overall_rating'].max()}\")\n",
    "print(f\"Mean: {df['overall_rating'].mean():.2f}\")\n",
    "print(f\"Median: {df['overall_rating'].median():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall rating statistics\n",
    "print(\"Overall Rating Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(df['overall_rating'].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Statistics by Position:\")\n",
    "print(\"=\"*60)\n",
    "position_stats = df.groupby('position')['overall_rating'].describe()\n",
    "print(position_stats.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed statistics\n",
    "print(\"\\nDetailed Position Statistics:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Count': df.groupby('position')['overall_rating'].count(),\n",
    "    'Mean': df.groupby('position')['overall_rating'].mean(),\n",
    "    'Median': df.groupby('position')['overall_rating'].median(),\n",
    "    'Std': df.groupby('position')['overall_rating'].std(),\n",
    "    'Variance': df.groupby('position')['overall_rating'].var(),\n",
    "    'Min': df.groupby('position')['overall_rating'].min(),\n",
    "    'Max': df.groupby('position')['overall_rating'].max(),\n",
    "    'Range': df.groupby('position')['overall_rating'].apply(lambda x: x.max() - x.min()),\n",
    "    'IQR': df.groupby('position')['overall_rating'].apply(lambda x: x.quantile(0.75) - x.quantile(0.25)),\n",
    "    'SE': df.groupby('position')['overall_rating'].apply(lambda x: x.std() / np.sqrt(len(x)))\n",
    "})\n",
    "\n",
    "print(summary.round(2))\n",
    "\n",
    "# Position percentages\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Position Distribution (%)\")\n",
    "print(\"=\"*60)\n",
    "pct = (df['position'].value_counts() / len(df) * 100).sort_index()\n",
    "for pos, percent in pct.items():\n",
    "    print(f\"{pos}: {percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "colors_pos = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "\n",
    "# 1. Box Plot by Position\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "df.boxplot(column='overall_rating', by='position', ax=ax1, patch_artist=True)\n",
    "ax1.set_title('Overall Rating by Position', fontweight='bold', fontsize=12)\n",
    "ax1.set_xlabel('Position')\n",
    "ax1.set_ylabel('Overall Rating')\n",
    "plt.sca(ax1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# 2. Violin Plot\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "sns.violinplot(data=df, x='position', y='overall_rating', ax=ax2, palette=colors_pos)\n",
    "ax2.set_title('Rating Distribution by Position', fontweight='bold', fontsize=12)\n",
    "ax2.set_xlabel('Position')\n",
    "ax2.set_ylabel('Overall Rating')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Bar Plot with Error Bars\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "means = df.groupby('position')['overall_rating'].mean().sort_values(ascending=False)\n",
    "sems = df.groupby('position')['overall_rating'].sem()[means.index]\n",
    "bars = ax3.bar(range(len(means)), means, yerr=sems, capsize=8, \n",
    "               alpha=0.8, color=colors_pos, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_xticks(range(len(means)))\n",
    "ax3.set_xticklabels(means.index, rotation=45, ha='right')\n",
    "ax3.set_title('Mean Rating ± SE by Position', fontweight='bold', fontsize=12)\n",
    "ax3.set_ylabel('Mean Overall Rating')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "for i, (m, se) in enumerate(zip(means, sems)):\n",
    "    ax3.text(i, m + se + 0.5, f'{m:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Histogram overlay\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "for i, pos in enumerate(df['position'].unique()):\n",
    "    pos_data = df[df['position'] == pos]['overall_rating']\n",
    "    ax4.hist(pos_data, alpha=0.5, label=pos, bins=15, color=colors_pos[i])\n",
    "ax4.set_title('Rating Distribution Overlay', fontweight='bold', fontsize=12)\n",
    "ax4.set_xlabel('Overall Rating')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Density Plot\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "for i, pos in enumerate(df['position'].unique()):\n",
    "    pos_data = df[df['position'] == pos]['overall_rating']\n",
    "    pos_data.plot(kind='density', ax=ax5, label=pos, color=colors_pos[i], linewidth=2.5)\n",
    "ax5.set_title('Density Plot by Position', fontweight='bold', fontsize=12)\n",
    "ax5.set_xlabel('Overall Rating')\n",
    "ax5.legend()\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# 6. Swarm plot (sample)\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "sample_df = df.groupby('position').sample(n=50, random_state=42)\n",
    "sns.swarmplot(data=sample_df, x='position', y='overall_rating', \n",
    "              ax=ax6, palette=colors_pos, size=3, alpha=0.6)\n",
    "means_all = df.groupby('position')['overall_rating'].mean()\n",
    "for i, pos in enumerate(means_all.index):\n",
    "    ax6.scatter(i, means_all[pos], color='red', s=300, marker='D', \n",
    "               zorder=10, edgecolors='darkred', linewidths=2)\n",
    "ax6.set_title('Sample Players with Means (n=50/position)', fontweight='bold', fontsize=12)\n",
    "ax6.set_ylabel('Overall Rating')\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 7. Position comparison: Preferred Foot\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "foot_stats = df.groupby('preferred_foot')['overall_rating'].agg(['mean', 'sem'])\n",
    "colors_foot = ['#3498db', '#e74c3c']\n",
    "bars = ax7.bar(range(len(foot_stats)), foot_stats['mean'], \n",
    "               yerr=foot_stats['sem'], capsize=10, \n",
    "               color=colors_foot, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax7.set_xticks(range(len(foot_stats)))\n",
    "ax7.set_xticklabels(foot_stats.index)\n",
    "ax7.set_title('Rating by Preferred Foot', fontweight='bold', fontsize=12)\n",
    "ax7.set_ylabel('Mean Overall Rating')\n",
    "ax7.grid(axis='y', alpha=0.3)\n",
    "for i, (m, se) in enumerate(zip(foot_stats['mean'], foot_stats['sem'])):\n",
    "    ax7.text(i, m + se + 0.3, f'{m:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 8. Variance comparison\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "variances = df.groupby('position')['overall_rating'].var().sort_values(ascending=False)\n",
    "bars = ax8.bar(range(len(variances)), variances, \n",
    "               color=colors_pos, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax8.set_xticks(range(len(variances)))\n",
    "ax8.set_xticklabels(variances.index, rotation=45, ha='right')\n",
    "ax8.set_title('Variance by Position', fontweight='bold', fontsize=12)\n",
    "ax8.set_ylabel('Variance')\n",
    "ax8.grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(variances):\n",
    "    ax8.text(i, v + 1, f'{v:.1f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 9. Count and percentage table\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "ax9.axis('tight')\n",
    "ax9.axis('off')\n",
    "table_data = []\n",
    "for pos in df['position'].value_counts().sort_index().index:\n",
    "    count = len(df[df['position'] == pos])\n",
    "    pct = count / len(df) * 100\n",
    "    mean = df[df['position'] == pos]['overall_rating'].mean()\n",
    "    std = df[df['position'] == pos]['overall_rating'].std()\n",
    "    table_data.append([pos, count, f'{pct:.1f}%', f'{mean:.1f}', f'{std:.1f}'])\n",
    "\n",
    "table = ax9.table(cellText=table_data,\n",
    "                 colLabels=['Position', 'N', '%', 'Mean', 'SD'],\n",
    "                 cellLoc='center',\n",
    "                 loc='center',\n",
    "                 colColours=['lightgray']*5)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "ax9.set_title('Summary Statistics Table', fontweight='bold', pad=20, fontsize=12)\n",
    "\n",
    "plt.savefig('fifa_eda_comprehensive.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization saved as 'fifa_eda_comprehensive.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ANOVA Assumptions Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Normality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"NORMALITY TEST (Shapiro-Wilk Test)\")\n",
    "print(\"=\"*70)\n",
    "print(\"H₀: Data is normally distributed\")\n",
    "print(\"Sample size note: With large samples (n>50), test may be overly sensitive\\n\")\n",
    "\n",
    "normality_results = []\n",
    "\n",
    "for position in sorted(df['position'].unique()):\n",
    "    pos_data = df[df['position'] == position]['overall_rating']\n",
    "    \n",
    "    # For large samples, Shapiro-Wilk can be overly sensitive\n",
    "    # Use a sample if n > 5000\n",
    "    if len(pos_data) > 5000:\n",
    "        test_data = pos_data.sample(5000, random_state=42)\n",
    "        note = \" (sampled)\"\n",
    "    else:\n",
    "        test_data = pos_data\n",
    "        note = \"\"\n",
    "    \n",
    "    stat, p_value = shapiro(test_data)\n",
    "    is_normal = p_value > 0.05\n",
    "    \n",
    "    normality_results.append({\n",
    "        'Position': position,\n",
    "        'n': len(pos_data),\n",
    "        'W-stat': round(stat, 4),\n",
    "        'P-value': round(p_value, 4),\n",
    "        'Normal?': '✓' if is_normal else '✗'\n",
    "    })\n",
    "    \n",
    "    print(f\"{position}{note}:\")\n",
    "    print(f\"  n = {len(pos_data)}\")\n",
    "    print(f\"  W-statistic = {stat:.4f}\")\n",
    "    print(f\"  P-value = {p_value:.4f}\")\n",
    "    print(f\"  Result: {'✓ Appears normal' if is_normal else '✗ May not be normal'}\\n\")\n",
    "\n",
    "norm_df = pd.DataFrame(normality_results)\n",
    "print(\"Summary:\")\n",
    "print(norm_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NOTE: ANOVA is robust to moderate deviations from normality,\")\n",
    "print(\"especially with large, balanced samples (Central Limit Theorem).\")\n",
    "print(\"Visual inspection (Q-Q plots) is also important.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Homogeneity of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"HOMOGENEITY OF VARIANCE (Levene's Test)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "groups = [df[df['position'] == pos]['overall_rating'] \n",
    "          for pos in sorted(df['position'].unique())]\n",
    "stat, p_value = levene(*groups)\n",
    "\n",
    "print(f\"\\nLevene's Statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "\n",
    "print(\"\\nGroup Variances and Standard Deviations:\")\n",
    "for pos in sorted(df['position'].unique()):\n",
    "    var = df[df['position'] == pos]['overall_rating'].var()\n",
    "    std = df[df['position'] == pos]['overall_rating'].std()\n",
    "    print(f\"  {pos:12s}: σ² = {var:6.2f}, σ = {std:5.2f}\")\n",
    "\n",
    "variances = [df[df['position'] == pos]['overall_rating'].var() \n",
    "             for pos in sorted(df['position'].unique())]\n",
    "var_ratio = max(variances) / min(variances)\n",
    "print(f\"\\nVariance Ratio (max/min): {var_ratio:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if p_value > 0.05:\n",
    "    print(\"✓ Variances appear homogeneous (equal)\")\n",
    "    print(\"  Standard ANOVA is appropriate\")\n",
    "else:\n",
    "    print(\"⚠ Variances may not be equal\")\n",
    "    print(\"  Consider: Welch's ANOVA\")\n",
    "\n",
    "if var_ratio <= 3:\n",
    "    print(f\"\\nVariance ratio ({var_ratio:.2f}) is acceptable (rule of thumb: <3)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Variance ratio ({var_ratio:.2f}) exceeds rule of thumb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Visual Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Q-Q plots for each position (sample for clarity)\n",
    "positions = sorted(df['position'].unique())\n",
    "for idx, pos in enumerate(positions):\n",
    "    if idx < 4:  # Only 4 positions\n",
    "        pos_data = df[df['position'] == pos]['overall_rating']\n",
    "        # Sample if too many points\n",
    "        if len(pos_data) > 300:\n",
    "            pos_data = pos_data.sample(300, random_state=42)\n",
    "        \n",
    "        row = idx // 2\n",
    "        col = idx % 2\n",
    "        stats.probplot(pos_data, dist=\"norm\", plot=axes[row, col])\n",
    "        axes[row, col].set_title(f'Q-Q Plot: {pos}', fontweight='bold')\n",
    "        axes[row, col].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fifa_qq_plots.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Q-Q plots saved as 'fifa_qq_plots.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. One-Way ANOVA: Ratings by Position\n",
    "\n",
    "**Hypotheses:**\n",
    "- **H₀**: μ_Attacker = μ_Midfielder = μ_Defender = μ_Goalkeeper\n",
    "- **H₁**: At least one position has a different mean rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ONE-WAY ANOVA: Overall Rating by Position\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Perform ANOVA\n",
    "position_groups = [df[df['position'] == pos]['overall_rating'].values \n",
    "                   for pos in sorted(df['position'].unique())]\n",
    "f_stat, p_value = f_oneway(*position_groups)\n",
    "\n",
    "print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "\n",
    "# Degrees of freedom\n",
    "k = len(position_groups)\n",
    "n = len(df)\n",
    "df_between = k - 1\n",
    "df_within = n - k\n",
    "\n",
    "print(f\"\\nDegrees of Freedom:\")\n",
    "print(f\"  Between groups: {df_between}\")\n",
    "print(f\"  Within groups: {df_within}\")\n",
    "print(f\"  Total: {n - 1}\")\n",
    "\n",
    "# Effect size\n",
    "grand_mean = df['overall_rating'].mean()\n",
    "ss_between = sum([len(df[df['position'] == pos]) * \n",
    "                  (df[df['position'] == pos]['overall_rating'].mean() - grand_mean)**2 \n",
    "                  for pos in df['position'].unique()])\n",
    "ss_total = sum((df['overall_rating'] - grand_mean)**2)\n",
    "eta_squared = ss_between / ss_total\n",
    "\n",
    "ms_between = ss_between / df_between\n",
    "ms_within = (ss_total - ss_between) / df_within\n",
    "omega_squared = (ss_between - df_between * ms_within) / (ss_total + ms_within)\n",
    "\n",
    "print(f\"\\nEffect Sizes:\")\n",
    "print(f\"  Eta-squared (η²): {eta_squared:.4f}\")\n",
    "print(f\"  Omega-squared (ω²): {omega_squared:.4f}\")\n",
    "\n",
    "if eta_squared < 0.01:\n",
    "    effect = \"negligible\"\n",
    "elif eta_squared < 0.06:\n",
    "    effect = \"small\"\n",
    "elif eta_squared < 0.14:\n",
    "    effect = \"medium\"\n",
    "else:\n",
    "    effect = \"large\"\n",
    "\n",
    "print(f\"\\nEffect Size: {effect.upper()}\")\n",
    "print(f\"({eta_squared*100:.2f}% of rating variance explained by position)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"✓ SIGNIFICANT RESULT (p = {p_value:.6f} < {alpha})\")\n",
    "    print(\"\\nCONCLUSION:\")\n",
    "    print(\"There IS a statistically significant difference in overall ratings\")\n",
    "    print(\"across different playing positions.\")\n",
    "else:\n",
    "    print(f\"✗ NON-SIGNIFICANT (p = {p_value:.6f} >= {alpha})\")\n",
    "    print(\"\\nCONCLUSION:\")\n",
    "    print(\"No statistically significant difference in ratings by position.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed ANOVA Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels ANOVA table\n",
    "model = ols('overall_rating ~ C(position)', data=df).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "\n",
    "print(\"\\nDetailed ANOVA Table:\")\n",
    "print(\"=\"*70)\n",
    "print(anova_table)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Model Statistics:\")\n",
    "print(f\"R-squared: {model.rsquared:.4f}\")\n",
    "print(f\"Adjusted R-squared: {model.rsquared_adj:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Post-Hoc Analysis: Tukey HSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < 0.05:\n",
    "    print(\"=\"*70)\n",
    "    print(\"POST-HOC TEST: Tukey HSD\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    tukey = pairwise_tukeyhsd(endog=df['overall_rating'], \n",
    "                              groups=df['position'], \n",
    "                              alpha=0.05)\n",
    "    \n",
    "    print(tukey)\n",
    "    \n",
    "    tukey_df = pd.DataFrame(data=tukey.summary().data[1:], \n",
    "                           columns=tukey.summary().data[0])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Detailed Pairwise Comparisons:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for idx, row in tukey_df.iterrows():\n",
    "        g1, g2 = row['group1'], row['group2']\n",
    "        meandiff = float(row['meandiff'])\n",
    "        p_adj = float(row['p-adj'])\n",
    "        reject = row['reject']\n",
    "        \n",
    "        mean1 = df[df['position'] == g1]['overall_rating'].mean()\n",
    "        mean2 = df[df['position'] == g2]['overall_rating'].mean()\n",
    "        \n",
    "        print(f\"\\n{g1} vs {g2}:\")\n",
    "        print(f\"  Mean {g1}: {mean1:.2f}\")\n",
    "        print(f\"  Mean {g2}: {mean2:.2f}\")\n",
    "        print(f\"  Difference: {meandiff:.2f} rating points\")\n",
    "        print(f\"  P-adj: {p_adj:.4f}\")\n",
    "        print(f\"  {'✓ SIGNIFICANT' if reject else '✗ Not significant'}\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"POST-HOC TEST: Not Applicable\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Overall ANOVA not significant - post-hoc tests not needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Alternative Analysis: Preferred Foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BONUS ANALYSIS: Rating by Preferred Foot (Independent t-test)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "right_foot = df[df['preferred_foot'] == 'Right']['overall_rating']\n",
    "left_foot = df[df['preferred_foot'] == 'Left']['overall_rating']\n",
    "\n",
    "print(f\"\\nRight-footed players: n = {len(right_foot)}, mean = {right_foot.mean():.2f}\")\n",
    "print(f\"Left-footed players:  n = {len(left_foot)}, mean = {left_foot.mean():.2f}\")\n",
    "\n",
    "# Independent t-test\n",
    "t_stat, t_p = stats.ttest_ind(right_foot, left_foot)\n",
    "\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {t_p:.6f}\")\n",
    "\n",
    "# Effect size (Cohen's d)\n",
    "pooled_std = np.sqrt(((len(right_foot)-1)*right_foot.var() + \n",
    "                      (len(left_foot)-1)*left_foot.var()) / \n",
    "                     (len(right_foot) + len(left_foot) - 2))\n",
    "cohens_d = (right_foot.mean() - left_foot.mean()) / pooled_std\n",
    "\n",
    "print(f\"\\nCohen's d: {cohens_d:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if t_p < 0.05:\n",
    "    print(f\"✓ SIGNIFICANT (p < 0.05)\")\n",
    "    print(\"Preferred foot IS associated with different ratings\")\n",
    "else:\n",
    "    print(f\"✗ NOT SIGNIFICANT (p >= 0.05)\")\n",
    "    print(\"No evidence that preferred foot affects overall rating\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_value < 0.05:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Mean comparison with significance\n",
    "    means = df.groupby('position')['overall_rating'].mean().sort_values(ascending=False)\n",
    "    sems = df.groupby('position')['overall_rating'].sem()[means.index]\n",
    "    \n",
    "    x_pos = range(len(means))\n",
    "    bars = axes[0].bar(x_pos, means, yerr=sems, capsize=10,\n",
    "                       alpha=0.8, color=colors_pos, edgecolor='black', linewidth=2)\n",
    "    axes[0].set_xticks(x_pos)\n",
    "    axes[0].set_xticklabels(means.index, rotation=45, ha='right')\n",
    "    axes[0].set_title('Mean Overall Rating by Position\\n(with significance bars)',\n",
    "                     fontweight='bold', fontsize=13)\n",
    "    axes[0].set_ylabel('Overall Rating')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add significance bars\n",
    "    y_max = (means + sems).max()\n",
    "    sig_pairs = []\n",
    "    for idx, row in tukey_df.iterrows():\n",
    "        if row['reject']:\n",
    "            g1_idx = list(means.index).index(row['group1'])\n",
    "            g2_idx = list(means.index).index(row['group2'])\n",
    "            sig_pairs.append((g1_idx, g2_idx, idx))\n",
    "    \n",
    "    for g1_idx, g2_idx, level in sig_pairs:\n",
    "        y_pos = y_max + 1 + level * 1.5\n",
    "        axes[0].plot([g1_idx, g2_idx], [y_pos, y_pos], 'k-', linewidth=2)\n",
    "        axes[0].text((g1_idx + g2_idx) / 2, y_pos + 0.3, '*', \n",
    "                    ha='center', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Tukey HSD CI plot\n",
    "    tukey.plot_simultaneous(xlabel='Rating Difference', \n",
    "                           ylabel='Position Comparison', ax=axes[1])\n",
    "    axes[1].set_title('Tukey HSD: 95% Confidence Intervals',\n",
    "                     fontweight='bold', fontsize=13)\n",
    "    axes[1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fifa_anova_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Results visualization saved as 'fifa_anova_results.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY: FIFA Player Ratings ANOVA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. RESEARCH QUESTION:\")\n",
    "print(\"   Do overall ratings differ significantly across player positions?\")\n",
    "\n",
    "print(\"\\n2. SAMPLE:\")\n",
    "print(f\"   Total players: n = {len(df)}\")\n",
    "for pos in sorted(df['position'].unique()):\n",
    "    count = len(df[df['position'] == pos])\n",
    "    mean = df[df['position'] == pos]['overall_rating'].mean()\n",
    "    print(f\"   {pos:12s}: n = {count:3d}, mean = {mean:.2f}\")\n",
    "\n",
    "print(\"\\n3. ANOVA RESULTS:\")\n",
    "print(f\"   F({df_between}, {df_within}) = {f_stat:.3f}\")\n",
    "print(f\"   P-value: {p_value:.6f}\")\n",
    "print(f\"   Effect size (η²): {eta_squared:.4f} ({effect})\")\n",
    "\n",
    "print(\"\\n4. CONCLUSION:\")\n",
    "if p_value < 0.05:\n",
    "    print(\"   ✓ SIGNIFICANT DIFFERENCES FOUND\")\n",
    "    print(\"   Player position IS associated with different overall ratings.\")\n",
    "    \n",
    "    highest = df.groupby('position')['overall_rating'].mean().idxmax()\n",
    "    lowest = df.groupby('position')['overall_rating'].mean().idxmin()\n",
    "    print(f\"\\n   Highest rated: {highest}\")\n",
    "    print(f\"   Lowest rated: {lowest}\")\n",
    "else:\n",
    "    print(\"   ✗ NO SIGNIFICANT DIFFERENCES\")\n",
    "    print(\"   Overall ratings are similar across positions.\")\n",
    "\n",
    "print(\"\\n5. PREFERRED FOOT ANALYSIS:\")\n",
    "if t_p < 0.05:\n",
    "    print(f\"   ✓ Significant difference (p = {t_p:.4f})\")\n",
    "else:\n",
    "    print(f\"   ✗ No significant difference (p = {t_p:.4f})\")\n",
    "\n",
    "print(\"\\n6. PRACTICAL INTERPRETATION:\")\n",
    "if p_value < 0.05:\n",
    "    print(\"   • Position matters for player ratings in FIFA\")\n",
    "    print(f\"   • {eta_squared*100:.1f}% of rating variance explained by position\")\n",
    "    print(\"   • May reflect real-world positional value or game mechanics\")\n",
    "else:\n",
    "    print(\"   • FIFA ratings are balanced across positions\")\n",
    "    print(\"   • Position doesn't systematically affect overall rating\")\n",
    "    print(\"   • Individual player quality matters more than position\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Analysis Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided a comprehensive ANOVA analysis of FIFA player ratings across positions:\n",
    "\n",
    "1. ✓ Large-scale dataset analysis (1100 players)\n",
    "2. ✓ Complete assumption testing with considerations for large samples\n",
    "3. ✓ One-way ANOVA for position comparison\n",
    "4. ✓ Effect size calculations\n",
    "5. ✓ Post-hoc pairwise comparisons\n",
    "6. ✓ Bonus analysis: Preferred foot comparison (t-test)\n",
    "7. ✓ Practical interpretation for gaming context\n",
    "\n",
    "**Key Finding**: Determines whether FIFA's rating system assigns systematically different scores to players based on their position, revealing potential biases or balance in the game's player evaluation system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
